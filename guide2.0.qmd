---
title: "WildTrax User Guide"
format: 
  html:
    grid:
      sidebar-width: 300px
      body-width: 1100px
      margin-width: 100px
      gutter-width: 1.5rem
website:
  search: 
    location: navbar
    type: overlay
date: "`r format(Sys.time(), '%d %B, %Y')`"
author: 
  - name: "Alex MacPhail"
    affiliation: "Biodiversity Pathways Ltd."
  - name: "Another author"
    affiliation: "Another affiliation"
toc: true
toc-depth: 5
toc-location: left
number-sections: true
editor: visual
theme: simplex
styles: styles.css
include-in-header: |
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      const tocItems = document.querySelectorAll('.toc a');
      
      tocItems.forEach(item => {
        item.addEventListener('click', function(event) {
          // Prevent default behavior
          event.preventDefault();

          // Collapse all other sections
          tocItems.forEach(link => link.parentElement.classList.remove('expanded'));

          // Expand clicked section
          this.parentElement.classList.add('expanded');

          // Scroll to the linked section
          const targetId = this.getAttribute('href').substring(1);
          const targetElement = document.getElementById(targetId);
          if (targetElement) {
            targetElement.scrollIntoView({ behavior: 'smooth', block: 'start' });
          }
        });
      });
    });
  </script>
  <style>
    .toc .expanded {
      font-weight: bold;
    }
    .toc .expanded ul {
      display: block !important;
    }
    .toc ul {
      display: none;
    }
  </style>
---

```{r}
#| echo: false
library(DT)

```

------------------------------------------------------------------------

# The Basics üî∞ {#sec-the-basics}

![](assets/banner.png)

**WildTrax** is the leading platform for managing, storing, processing and sharing environmental sensor data. With WildTrax, you can:

-   Manage all components of environmental sensor and biological data from field metadata, to media, to species observations
-   Store data safely and securely while still making it accessible to users
-   Process environmental sensor data to a high degree of data quality and integrity
-   Share environmental sensor and biological data with other WildTrax users, collaborators and the public
-   Discover data in your study area or across the WildTrax system

**Environmental sensors** (such as autonomous recording units \[ARUs\] or remote cameras) are an increasingly common monitoring method used to measure environmental and ecological attributes across broad geographic scales. These sensors allow for automated collection of data over an extended period and can generate large amounts of valuable biological data.

**Biological data**, such as counts of animals, their behaviour, or other attributes, can be derived from environmental sensors. WildTrax seamlessly integrates such data across multiple sensors, with the additional capacity to incorporate data from point counts, a commonly used method for evaluating species‚Äô relative abundance, especially birds.

[**Open data**](https://wildtrax.ca/about/open-data/) is data that can be accessed, re-used or redistributed by anyone and is freely available in a usable and convenient format. Open data benefits the scientific community and society. Data accessibility allows users (e.g., researchers, conservation practitioners and the public) to find, manipulate and analyze data, as well as link data to other types of information. Open data can lead directly to conservation knowledge and action. This requires data to be usable, compatible with other datasets, and reliable.

------------------------------------------------------------------------

::: small-grey
The WildTrax platform was developed by the Alberta Biodiversity Monitoring Institute (ABMI) and the [University of Alberta](https://www.ualberta.ca/en/index.html). The [ABMI](https://abmi.ca) is an arm‚Äôs length, not-for-profit scientific organization that has been providing scientifically credible tools and information products on Alberta‚Äôs biodiversity and human footprint to provincial government, industry, environmental decision-makers, and Albertans since 2003. The ABMI has since become a global leader in the application and development of biodiversity monitoring.

WildTrax acknowledges that it was conceived and is developed on the territory of the N√©hiyaw (Cree), Niitsitapi (Blackfoot), M√©tis, Nakoda (Stoney), Dene, Haudenosaunee (Iroquois) and Anishinaabe (Ojibway/Saulteaux), lands that are now known as part of Treaties 6, 7 and 8 and homeland of the M√©tis. We respect the sovereignty, lands, histories, languages, knowledge systems and cultures of all First Nations, M√©tis and Inuit nations.

WildTrax is continuously improved based on user needs and stakeholder engagement processes. Sign up for the newsletter in [User settings](#sec-user-settings) or check out the [News](https://wildtrax.ca/resources/news/) page to get the most up-to-date feature releases. Each sensor in WildTrax is supported organizations who have help pave the way for a multi-sensor experience in WildTrax. Visit our full list of [Partners and Sponsors](https://wildtrax.ca/about/partners-and-sponsors/).
:::

::: {.callout-note collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
The pronoun ‚Äúyou‚Äù throughout this guide refers to the reader. ‚ÄúWe‚Äù refers to the WildTrax Team in general.
:::

------------------------------------------------------------------------

## Creating an account

You can explore WildTrax data for free anytime. While the [Data Discover](https://discover.wildtrax.ca) tool lets you browse and map public data without an account, creating an account unlocks roles and privileges to fully access and use the system. Visit [**wildtrax.ca**](wildtrax.ca) and click on the ![](assets/login.png){height="28px"} button in the top ribbon.

![](assets/login-home.png){.lightbox}

You can create a WildTrax using either a social media account, such as Google, or a username and password linked to your email address. After creating your account, you‚Äôll need to verify it through an email sent to your inbox. This step is required before you can start using your account. For a detailed walkthrough, <mark>check out the video tutorial below.</mark>.

::: {.callout-tip collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
### Video tutorial - Creating an account

{{< video https://www.youtube.com/watch?v=Oy_Fg4IYMEU >}}
:::

## Data hierarchy and permissions made simple

Your individual user account ensures data security and assigns specific roles within the system. Access to data is determined by several factors, including your role, location settings, and the publication status of projects. WildTrax uses a structured data hierarchy with permissions set the following levels to maintain controlled access.

- At the top level, [**Organizations**](#sec-organizations) bring together groups of researchers and users collaborating on diverse research initiatives. Organizations oversee equipment, manage locations and media, and have the ability to create projects using the media they own.

![](assets/organizations.png){.lightbox}

- [**Locations**](#sec-locations) are geographic sites where environmental sensors are deployed or biological data is collected. They link media and [equipment](#sec-equipment) metadata in WildTrax and are managed by organizations.

![](assets/locations.png){.lightbox}

- **Projects** are groups of specific media to address research questions or implement study designs. Projects can be one of three sensors: [ARUs](#sec-aru-projects), [cameras](#sec-camera-projects) or [point counts](#sec-point-count-projects).

![](assets/projects.png){.lightbox}

- **Tasks** are specific assignments given to users to process media, such as audio recordings or image sets, into biological data. Within each task, species **tags** are applied to extract meaningful information, such as species presence, absence, or counts, which contribute to further metrics.

<div style="display: flex; justify-content: center; gap: 40px;"> <img src="assets/aru-processing.png" alt="ARU Processing" style="width: 45%; height: auto;"><img src="assets/camera-processing.png" alt="Camera Processing" style="width: 45%; height: auto;"> </div>

- After processing, projects can be [**published**](#sec-publishing-and-sharing) in order to shared with other WildTrax users or the public. Projects will become available in the dashboard and within [**Data Discover**](discover.wildtrax.ca).

![](assets/data-discover-landing-page.png){.lightbox}

::: {.callout-tip collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
### Video tutorial - Data hierarchy

Check out this video tutorial on WildTrax's Hierarchy.

{{< video https://www.youtube.com/watch?v=g88-M6IH1X8&list=PLe2MuPH7fHN0nSZxNJUd7JANZQyxDcuV1&index=15 >}}
:::

As roles are assigned in the system, data is kept data secure and accessible only to the right people. Each user has their own account with your access depending on your role, which determines the tools, features, and data sets you can see and use. [Organization](#sec-organizations) and [project](#sec-aru-projects) data availability considers factors like [location settings](#sec-location-settings) and whether the data has been [published](#sec-published-and-sharing), ensuring it‚Äôs [shared responsibly and securely](https://wildtrax.ca/about/open-data/).

::: {.callout-tip collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
### Video tutorial - Privacy settings

Check out this video tutorial on WildTrax's Privacy Settings.

{{< video https://www.youtube.com/watch?v=xnfvLjwrJgY&list=PLe2MuPH7fHN0nSZxNJUd7JANZQyxDcuV1&index=16 >}}
:::

## Mastering data workflows

WildTrax provides robust tools to manage environmental sensor data. Following these steps will help you seamlessly integrate your data and maximize the platform's capabilities. The general life cycle of data within WildTrax involves:

- **Create an [Organization](#sec-organizations)**: Set up an organization to manage and store your data.\
- **Create a [Project](#sec-aru-projects)**: Establish a project to process your data to answer a specific question.\
- **Add Users**: Invite team members with specific roles to your organization and project for collaborative data management.\
- **Upload recordings or images**: Upload and organize your recordings and images files for upload and processing.
- **Create or Upload Tasks/Surveys**: Define tasks or upload surveys to guide data processing with specific methodology.
- **Process or Upload Tags/Observations**: Generate tags or observations during processing, or upload pre-existing ones.\
- **Verify and Quality Control**: Review and validate tags to ensure accuracy.\
- **Publish the Project**: Finalize and publish the project for access and use.

## Publishing and sharing data {#sec-publishing-and-sharing}

When the project is completed and all data processed, the status of the project can be changed to a published status. Project publication allows other WildTrax users, who are not project members, to access the media, metadata or species detections from the project either through the project dashboard or [Data Discover](#sec-data-discover). The publication status will control how data will become visible across the system. Project publication will also lock users from editing species detections and is considered the final version of the data. You can change the status of a project at any time. [Location](#sec-locations) and project membership settings will also determine what you and others can see. Ensure you have these correctly set before publishing a project. Here are some in-depth descriptions of each of the published statuses and what they mean.

::: {.callout-tip collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
### Video tutorial - Publishing data

Need to understand more about how to publish a project? Check out the video tutorial below.

{{< video https://www.youtube.com/watch?v=4SSVJ5ahpbo&list=PLe2MuPH7fHN0nSZxNJUd7JANZQyxDcuV1&index=11 >}}
:::

*Active Projects*

- **Active**: Active projects are currently being processed or designed, or are in the preliminary stages of data uploading. Use this status for any general use or if the project is actively being worked on. This is the default project status when it is first created.
- **Test**: Just getting started with an environmental sensor program? Or have some media you want to upload to test WildTrax‚Äôs functionalities? Use the Test status in these cases. Project data will not be visible in Data Downloads or Data Discover except to project members.

*Published Projects*

- **Published ‚Äì Private**: Project data will only be available to project members. Users will need to request access to the project in order to view any details such as species or locations.
- **Published ‚Äì Map Only**: Project data will be accessible through Data Discover but the media and report are not accessible to users who are not project members. If you‚Äôre not a project or organization member, the location buffering and visibility settings will apply.
- **Published ‚Äì Map + Report Only**: Project data become available to all WildTrax users through Data Downloads and Data Discover, however, the media is not accessible. Use this setting if you want to make your data publicly available but there are privacy concerns with your media. If you‚Äôre not a project or organization member, the location buffering and visibility settings will apply. This status does not exist for point counts since the sensor does not contain media.
- **Published ‚Äì Public**: All of the project data become available to any WildTrax user as well as the public in [Data Discover](#sec-data-discover). If you‚Äôre not a project or organization member, [location buffering and visibility settings](#sec-location-privacy-settings) will stil apply.

See more about sharing data within an open data network like WildTrax in the [Open Data](https://wildtrax.ca/about/open-data/) section.

## Recommended equipment

Proper equipment will enhance your experience and data quality using WildTrax. The following equipment is recommended for processing camera image data.

- A computer with a minimum screen size of 15‚Ä≥
- A stable, high speed internet connection

For acoustic data processing:

- Headphones with the following specifications:
- Stereo
- Circumaural (fully enclosing the ear)
- Minimum frequency response: 20 ‚Äì 20000 Hz
- No bass boost (flat frequency response)

------------------------------------------------------------------------

# Accounts, membership and permissions üë• {#sec-permissions}

WildTrax operates under a role-based access control system, meaning a user in the system represents an individual, not an organization or a group of people. This restricts access to authorized users and is a policy-neutral mechanism designed to create roles and privileges. These users can then collaborate to manage data or share data to answer broader scientific questions. This means your access to certain features, tools, or data may vary based on your permission level. For example, access to project data can be restricted by [location settings](#sec-location-settings) or the project's [publication status](#sec-publishing-and-sharing). Here's an overview of the key permissions levels:

- [Organization membership](#sec-organization-membership) all you to see or govern access to all projects and data under an Organization. Permissions at the Organization level include:
    - Administrator
    - Read-Only Member
- [Location visibility](#sec-location-settings) and buffering controls whether whether locations are visible or hidden for privacy purposes
- [Project membership](#sec-aru-project-users) dictates what you can do within specific projects such as uploading media, processing tasks or verify species tags roles include:
    - Administrator
    - Tagger
    - Read-Only Member
- [Project Status](#sec-publishing-and-sharing) dictates whether members or the public can access a project or its data. Active and Test projects are accessible only to members of the respective Organization or Project. Once a project is published, the visibility and access to its data depend on the permission level assigned to the user.

The interaction of these permission levels defines the scope of data you can view and how you can engage with it on WildTrax. Since Organizations are parent entities to projects, Organization administrators automatically inherit Project Administrator privileges. However, users assigned read-only access at the project level will not gain access to the parent Organization.

If certain components are not available or options are locked or greyed out, it is likely that you do not have access to those data. member of that organization. **Requesting access** is the easiest way to gain higher level access by having [Organization](#sec-organizations) or [Project](#sec-aru-projects) administrators approve your access request. Click the drop-down arrow beside the organization name and then click ![](assets/request-access-button.png){height="30px"} and fill in the Request Access form to request membership. Administrators of the organization will receive a notification and will either approve or deny your membership request. Clearly specify the type of access privileges you are requesting, such as read-only access or administrator-level permissions.

![](assets/request-access.png){.lightbox}

## User settings {#sec-user-settings}

The user settings dashboard can be accessed by clicking on your username in the top right corner of the top ribbon when you‚Äôre logged into the system, for example ![](assets/user-name.png){height="32px"}.

The user settings dashboard controls the following properties related to your account:

-   **Name**: your full name
-   **Initials**: an acronym or set of initials you can use to define an observer or user
-   **Subscribe to Newsletter**: a toggle that will opt you in for occasional WildTrax newsletters delivered to your email
-   **Language**: your default language. Currently available in English and French.
-   **Affiliation (optional)**: the organization, institution or group of which you‚Äôre a member or user in the system.

Once you‚Äôve made your desired changes, click the ![](assets/update.png){height="30px"} button.

![](assets/user-settings-panel.png){.lightbox}

::: {.callout-note collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
The JWT token is a unique authentication token used for accessing WildTrax via the **wildrtrax** package associated to your email. It also enables secure and flexible integration with WildTrax APIs for building custom applications.
:::

You can change the language in the site at anytime from the top ribbon toggle ![](assets/top-ribbon-language.png){height="30px"}. If you want to permanently change the language, go to [User settings](#sec-user-settings) and change it to your preferred language.

------------------------------------------------------------------------

# Data Discover üåç {#sec-data-discover}

![](assets/data-discover-landing-page.png){.lightbox}

**Data Discover** is the central hub for exploring environmental sensor data in WildTrax. Data Discover allows you to see which organizations have published data on WildTrax and which species were detected, and explore media elements such as images and sounds captured in the environment. In Data Discover, you can search for data from ARUs, cameras, and point counts, using a variety of attribute filters, and create summary statistics within a dynamic mapping interface where you can gain a comprehensive understanding of environmental sensor data in an area that interests you.

After using Data Discover, you may have found an organization or project that you‚Äôre interested in ‚Äì so what‚Äôs next? Head over to either the [Organization](#sec-organizations) or [Project](#sec-aru-projects) dashboard to find out more about the data owners or the project or to request access to the data. Once you are granted access by the project administrators, proceed to Data Downloads to acquire the data.

::: {.callout-tip icon="false" collapse="true" style="padding: 20px;"}
Advanced users can also download data using the package [wildrtrax](https://abbiodiversity.github.io/wildrtrax) to download data.
:::

## Filters

Use attribute filters or select a specific sensor to search available data within Data Discover. On the left side of the interface, the Filter Panel houses various filters for refining your search. Results will be displayed on the map and in a table below. Ensure locations with spatial coordinates are visible on the map, and toggle between different base maps (light or satellite) in the top right corner.

![Data Discover Filters](assets/data-discover-filter-panel.png){.lightbox}

You can search by:

-   **Taxonomy**: Classify data based on class, order, family, and genus.
-   **Species**: Search for individual species or add multiple species to your selection.
-   [**Organizations**](#sec-organizations)
-   **Projects** by sensor, either [ARU](#sec-aru-projects), [camera](#ec-camera-projects), or [point count](#sec-point-count-projects)
-   **Dates and times** (also months and hours) within set intervals or with start and end dates

Note you must select one sensor must be selected before you can proceed with other You can delete the selected options in the filter panel at the bottom left of the panel using Delete Layer.

## Layers

Explore data in depth with up to five customizable layers. Create a new layer by clicking on the ![](assets/data-discover-plus-layer.png){height="30px"} icon. The colours for the points correspond to the layer in the filter panel. By hovering over the layer number, you can duplicate an existing layer ![](assets/data-discover-duplicate-layer.png){height="30px"} to preserve its results and further refine your exploration, use the garbage can icon ![](assets/data-discover-delete-layer.png){height="30px"} to delete the current layer, and the ![](assets/data-discover-layer-visibility.png){height="30px"} to control the visibility of the layer on the map. Each summary insight in the bottom-right corner is also colour-coded to correspond with the layer's filter.

![Data Discover Layers](assets/data-discover-layers.png){.lightbox}

## Searching an area of interest

Refine your selection to an area of interest using the polygon tool in the top-right corner ![](assets/data-discover-polygon-tool.png){height="30px"}. One polygon per layer is supported. To draw a polygon, click the tool, then click on the map to define points, completing the shape by clicking back to the original point. To remove a polygon, select it on the map and click the Garbage can icon.

![Data Discover Polygon Tool](assets/data-discover-polygon.png){.lightbox}

![Data Discover one polygon per layer](assets/data-discover-two-polygons.png){.lightbox}

## Summaries and insights

Click the **Layer Summary** icon in the bottom-right corner to view a visual representation of the organizations, projects, species, and tag counts in your layer. This action opens the Summary Window, where you can explore detailed insights. Within the Summary Window, the Summary tab provides an overview, while the Media tab offers media-specific details.

![Summary window](assets/data-discover-summaries.png){.lightbox}

-   **Summary Tab**: View pie charts detailing the number of organizations, projects, and species for your selected area. Scroll down for bar charts representing tag counts across months and hours.
-   **Media Tab**: Tiles correspond to species tags. Play audio clips or view images. Observe the minimum and maximum frequency of an audio clip in its ARU spectogram. Note that point counts do not include any media.

![](assets/media-tab.png){.lightbox}

------------------------------------------------------------------------

# Organizations üè¢ {#sec-organizations}

**Organizations** sit at the top of the WildTrax hierarchy and are the central entity to which environmental sensor data, biological data and metadata are associated. When in doubt, if you‚Äôre looking for any information in WildTrax, you can likely find it under the organization. Organizations represent groups of users who collect data, design and publish projects, manage equipment and survey locations. Organizations allow you to coordinate efforts with multiple WildTrax users to create a structured, standardized dataset. Examples of organizations include government branches, industry, research labs and non-profits.

![](assets/organizations.png){.lightbox}

::: {.callout-tip collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
You can jump to any Organization or Project at any time using `CTRL + /`. This will bring up a search prompt allowing you to navigate to any Organization or Project you have access to.

![](assets/global-search.png){.lightbox}
:::

## Create an organization

Click on ![](assets/my-data.png){height="30px"} in the top ribbon, followed by My Organizations. This will take you to the organization dashboard. Click the ![](assets/create-organization.png){height="30px"} button, from here the Organization Settings form will appear.

![](assets/new-organization.png)

Fill in the fields in the form and click Save. A WildTrax administrator will need to confirm your identity before approving your new Organization request. If you‚Äôre having any technical difficulties creating an Organization contact WildTrax Support at support\@widltrax.ca.

```{r}
#| eval: true
#| include: true
#| echo: false

data <- data.frame(
  Field = c(
    "Organization acronym", 
    "Organization full name", 
    "Institution / company / group", 
    "Storage location", 
    "Default location buffering", 
    "Default buffer radius (m)", 
    "Allow location reports", 
    "Default visit image access", 
    "Human blurring", 
    "Organization description", 
    "Default settings"
  ),
  Description = c(
    "A short-hand name for your organization (e.g., ABMI).",
    "The full name of the organization.",
    "The institution the organization is part of, such as a university or government branch.",
    "Where the data will be stored.",
    "The organization‚Äôs default for whether the coordinates entered are exact ('True Locations') or randomly offset ('Buffered Locations') by a specified radius.",
    "The organization‚Äôs default location buffer radius (in metres). The radius of the buffer around the location within which the coordinates are randomized (0 if not hidden).",
    "Enables location summary reports when turned on.",
    "Default privacy setting for visit photos uploaded to the organization.",
    "An organization-wide setting for human blurring in images. Options include 'Blur for anonymous users,' 'Blur for everyone,' and 'Blur for non-admins.'",
    "A short description of the organization.",
    "Default settings can be applied at the organization level for tasks such as location buffering or visit image access."
  )
)

datatable(
  data, 
  colnames = c("Field", "Description"), 
  options = list(
    pageLength = 10, 
    autoWidth = TRUE, 
    dom = 't'
  )
)
```

### Media storage

WildTrax offers multiple choices for data storage designed to support the platform's growing user base and evolving data management needs. Each Organization must select the storage location where they need to store their media. This allows you to quickly access an image or recording at a moment's need. The current options as of `r format(Sys.Date(), "%B %d, %Y")` currently include:

-   **WildTrax Live Servers**: Hosted at the University of Alberta in Edmonton, Alberta, Canada. These servers provide a cost-effective and sustainable solution with live and off-site backups using [Amazon Deep Glacier](https://aws.amazon.com/s3/storage-classes/glacier/), ensuring secure and reliable data storage for Canadian and international organizations.
    -   <mark>Free Storage Tier: 250 GB, Annual Cost: \$ 75.00 CAD / TB</mark>
-   [**Amazon Web Services (AWS)**](https://aws.amazon.com/): Retained as an option for users requiring cloud-based storage with global accessibility and high-performance capabilities with international storage base options. Current locations include **Oregon** and **Montreal**.
    -   <mark>Free Storage Tier: 50 GB, Annual Cost: \$ 360.00 CAD / TB</mark>

The selection of a default storage location now balances data sovereignty, cost efficiency, and upload/download performance based on geographic proximity. For detailed guidance, refer to WildTrax‚Äôs [Terms and Conditions of Use and Data Access Policies](https://wildtrax.ca/about/policies/), or contact info\@wildtrax.ca for additional support.

::: {.callout-note collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
Note that each option comes with a cost-recovery model when Organizations exceed a certain limit of data. Organizations will be charged for these storage fees on an annual basis starting in 2026.
:::

### Default privacy settings {#sec-default-privacy-settings}

Organizations can manage the privacy of locations and images within the system to control what other users can access when data becomes published and more widely available. Location privacy can also be managed individually; see [Location privacy settings](#sec-location-settings) for more information.

![](assets/abmi-organization.png){.lightbox}

For location privacy, two approaches are available within the **Default Location Buffering** field.

-   **True locations**: Upload exact coordinates into the system. If a buffer is added, non-members or public viewers will only see buffered locations. This allows you to have access to and manage the true locations within WildTrax while simulatenously allowing users to gain access to the data without knowing the true coordinates
-   **Buffered locations**: Supply pre-buffered coordinates to the system, specifying the radius used. This ensures the displayed locations are already obscured as intended.

The **Allow Location Reports** feature enables you to create shareable links for external audiences, such as collaborators or landowners, without granting them privileges or exposing unnecessary details about your organization. The **Default Location Photo Access** field governs global permissions for accessing [location photos](#sec-location-photos).

-   **Private**: Only members of the organization or project can view the location photos even if the project is published
-   **Project-level Access**: members of the project can view the location photos, but non-members cannot even if the project is published
-   **Publicly Viewable**: if a project is published, non-members can view the location photos within the tasks

**Human Blurring** applies organization-wide settings to blur humans detected in images. The available options include:

-   **Blur for anonymous users (if applicable)**: images of humans will be blurred for all non-read only/non-admin WildTrax users if project data is visible based on the project status.
-   **Blur for non-admins**: images of humans will be blurred for all WildTrax users regardless of their organization or project membership.
-   **Blur for everyone**: images of humans will be blurred for all read-only WildTrax users.

Choose the option that best aligns with your needs and data privacy policies. For example, if you opt out of Human Blurring, you acknowledge that uploaded images‚Äîand those potentially shared publicly‚Äîmay include humans, accepting the associated risks.

![](assets/human-blurring.png){.lightbox}

### Organization membership {#sec-organization-membership}

After your organization is approved, the ![](assets/users-menu.png){height="40px"} option will appear in the context menu. This will allow you to search for and add any WildTrax user to your organization either as an administrator or read-only member.

![](assets/assign-org-users.png)

**Organization administrators** collaboratively manage the media and metadata of the organization and have the ability to:

-   Enjoy administrator privileges by default on all projects belonging to the Organization
-   Add WildTrax users to the organization or its projects
-   Read and write to organizational locations
-   Read and write to the visit, equipment, deployment and media metadata

**Organization read-only members** can:

-   Read the unbuffered locations, i.e., read-only members can see the true locations if they are buffered but cannot modify them
-   Read the visit, equipment, and media metadata
-   Enjoy read-only access to all organizational projects
-   The organization dashboard lists all organizations in WildTrax. The View Only My Organizations toggle in the top-right filters the list to only organizations you‚Äôre a part of.

If the organization is greyed out, you are not a member of that organization. Click the drop-down arrow beside the organization name and then click ![](assets/request-access-button.png){height="40px"} and fill in the Request Access form to request membership. Administrators of the organization will receive a notification and will either approve or deny your membership request.

![](assets/request-access.png){.lightbox}

Once the organization has been approved, The **principal investigators** of the organization are users who respond to access requests related to the organization or its projects. Without a principal or secondary investigator, all organization and project access requests will default to organization then project administrators, in order. Once you create an Organization, you can add yourself as one of the principal investigators or [add more users](#sec-organization-membership) to your Organization and then assign them those privileges.

![](assets/principal-investigators.png){.lightbox}

### What's Next After Creating My Organization?

::: {.callout-question collapse="true" style="background-color: #f9f9f9; border-left: 5px solid #dc3545; padding: 15px; margin: 15px 0; color: #343a40;"}
**What Should I Do Next?**

**Manage Organization Metadata**

Optimize your organization's metadata by:

-   Adding [locations](#sec-locations), [location photos](#sec-location-photos), [visits](#sec-visits), [equipment inventories](#sec-equipment), [deployment information](#sec-deployment), or uploading [acoustic media](#sec-upload-recordings).\
-   Establishing location privacy by setting appropriate privacy levels‚Äîpublic, restricted, or private‚Äîtailored to your data-sharing needs.

**Create a Project**

-   **Define Your Research Questions**\
    Clearly outline the objectives or questions your project will address. This will help guide data setup and analysis.\
-   **Decide on an Upload Strategy**\
    Determine if recordings will be uploaded at the project level or organization level to align with your workflow.
-   **Assign Membership Privileges**\
    Define roles for project participants (e.g., read-only, tagger, admin) based on access requirements.

*Need more help? See [Accounts, Membership, and Permissions](#sec-permissions) for detailed guidance.*
:::

## Locations {#sec-locations}

![](assets/locations-tab.png){.lightbox}

**Locations** refer to the physical, geographic places at which environmental sensors were deployed and/or biological data was collected on the landscape. They are one of the most important components in WildTrax as media and metadata are linked by the location.

::: {.callout-note icon="false" collapse="true"}
All locations are stored exclusively as latitude and longitude coordinates in the [WGS84](https://epsg.io/4326) format.
:::

### Create locations

Click the Locations tab in your organization dashboard. Clicking ‚ÄùCreate Location‚Äù will open the location form, where you can add the spatial metadata to the location or configure the location‚Äôs settings. You only need to enter the location name, latitude and longitude in order to create a location. When you‚Äôve filled in the form click Save. The map tab will appear allowing you to visualize the point on the landscape. The location will also be visible on maps across WildTrax.

```{r}
#| eval: true
#| include: true
#| echo: false

data <- data.frame(
  Field = c(
    "Location", "Latitude", "Longitude", "Elevation (m)", 
    "Location visibility", "Location buffering", 
    "Buffer radius (m)", "Location description"
  ),
  Description = c(
    "Name of the location.",
    "Latitude in decimal degrees (max 10 digits)",
    "Longitude in decimal degrees (max 10 digits)",
    "Elevation above sea level (metres)",
    "'Visible,' 'Hidden ‚Äì Location,' or 'Hidden ‚Äì Location+Data'",
    "True or Buffered Location",
    "Buffer radius (metres) for randomized coordinates (0 if not hidden)",
    "Brief description; more details in visit metadata"
  ),
  Example = c(
    "LOCATION-ABC", "54.11910100", "-118.1728210", "500", 
    "Visible", "True Location", "0", "Creek nearby, off game trail"
  )
)

datatable(data, 
          colnames = c("Field", "Description", "Example"), 
          options = list(pageLength = 10, autoWidth = TRUE))

```

::: {.callout-tip collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
Did you know locations are created in the organization when media are [uploaded via a project](#sec-upload-recordings-tasks)? If a location name already exists in the organization, WildTrax will append the media to it, and if it is a new location WildTrax will prompt you during the upload process if you want to add spatial coordinates to these new locations.

![](assets/aru-upload-coordinates.png)
:::

### Location privacy settings {#sec-location-settings}

You can manage a location‚Äôs privacy settings individually by clicking the ![](assets/pencil.png){height="30px"} icon next to the location name. These settings control what information users can access about a location and its associated data, ensuring secure and customizable access across the system. WildTrax offers organization administrators multiple tools to define how members view locations and their data, providing robust privacy options to protect sensitive information as needed.

The **location visibility** setting is used to hide locations and data from WildTrax users who are not part of the organization or project the location belongs to.

-   Use **Hidden ‚Äì Location** if you want to hide only the location‚Äîonly organization and project administrators will see the location in the maps across the system. Species data can still be downloaded by non-members but with no coordinates, non-members will not know where the data comes from.
-   Use **Hidden ‚Äì Location + Data** if you want to hide both the location and the species information. This setting will effectively hide everything from users who are not organization or project members.
-   Use **Visible** if you want the location and data to be visible to everyone once the project is published

If you are using Hidden ‚Äì Location + Data, you can refer to location reporting to learn how to share data with users who are not members of the organization or project. This may include landowners, collaborators, or other users to whom you do not wish to grant privileges but are still able to share your data.

**Location buffering** is another way to mask sensitive locations. You can use the location buffering toggle in two ways:

-   **True locations**: Upload exact coordinates into the system. If a buffer is added, non-members or public viewers will only see buffered locations. This allows you to have access to and manage the true locations within WildTrax while simulatenously allowing users to gain access to the data without knowing the true coordinates
-   **Buffered locations**: Supply pre-buffered coordinates to the system, specifying the radius used. This ensures the displayed locations are already obscured as intended.

The link to the [**location reports**](#sec-location-reports) is also available at the bottom of the form.

### Sync locations {#sec-location-sync}

WildTrax provides the flexibility to sync location data in batch by uploading and downloading location information and metadata. This feature allows you to manage and edit location data outside of WildTrax and sync it back with your modifications. To upload data, you need organization administrator privileges, but read-only members can still download data. To sync locations, first go to the menu ![](assets/dropdown-arrow.png){height="20px"} and select ![](assets/locations-sync-menu.png){height="30px"}:

-   **Download Location Data**: Click the ![](assets/download-sync-menu.png){height="30px"} to download the current list of all locations and metadata in your organization. If no metadata exists, a template CSV will be provided will column headers (see @tbl-location-sync).
-   **Edit the CSV File**: Open the downloaded CSV file and make any necessary changes or edits. You can modify existing entries or add new ones. Do not modify the fields beginning with *internal\_* as they are for WildTrax use only.
-   **Upload the Edited CSV**: Click the ![](assets/upload-sync-menu.png){height="30px"} button to upload your edited CSV. This will take you to the **Upload CSV** form. Select your local CSV file and click **Preview Changes** to review the updates.

::: {.callout-tip icon="false" collapse="true"}
Batch upload processes in WildTrax support **add** and **update** operations only; deletions are not allowed. For example, if you accidentally upload an empty CSV, no existing data will be deleted.
:::

```{r}
#| eval: true
#| echo: false
#| label: tbl-location-sync

library(DT)

location_sync <- tibble::tibble(
  value = c(
    "location", 
    "location_latitude", 
    "location_longitude", 
    "elevation", 
    "location_buffer_m", 
    "location_visibility", 
    "location_true_coordinates", 
    "comments", 
    "internal_wildtrax_id", 
    "internal_update_ts"
  )
)

datatable(
  location_sync,
  colnames = c("Column name"), 
  options = list(
    pageLength = 10,      
    dom = 't',         
    autoWidth = TRUE  
  ),
  caption = htmltools::tags$caption(
    style = 'caption-side: top; text-align: center;',
    'Location Sync Field Descriptions'
  )
)

```

### Merge locations

WildTrax allows you to merge multiple locations into one. This feature is particularly useful if a location has been visited multiple times but was assigned different names for each visit or if the locations represent the same physical place on the landscape. To merge locations:

-   Select the *source* location (the location you want to modify) and click the ![](assets/dropdown-arrow.png){height="20px"}, or right-click the location row and select ![](assets/merge-menu.png){height="30px"}.
-   The location merge form will appear. From the dropdown list, select the *target* location (the location to merge into).
-   Confirm your selection: the media from both locations will be combined, but only the metadata from the target location will be preserved.
-   Click ![](assets/merge-button.png){height="30px"} to complete the process. After merging, all data will be consolidated under the target location.

![](assets/merge-location-form.png){.lightbox}

::: {.callout-warning icon="false" collapse="true"}
Merging locations is an irreversible process. Double-check your selections before proceeding.

Merging locations is also only possible when one or both locations lack spatial coordinates (latitude and longitude). If only one location has coordinates, those will be retained during the merge. However, merging is not allowed if both locations contain different spatial coordinates.
:::

### Delete locations

You can delete locations using the ![](assets/delete-menu.png){height="30px"} option, accessible via the ![](assets/dropdown-arrow.png){height="20px"} next to any location name. However, if any data‚Äîsuch as visits, media, or tags‚Äîare associated with a location, deletion will not be allowed until those dependencies are removed (the delete button will appear greyed out). Detailed instructions for managing these dependencies can be found in the sections on projects and sensor types (ARU, camera, point count). Since locations serve as the foundation for all associated data, WildTrax has implemented safeguards to prevent accidental data loss, ensuring secure and reliable management of cascading data.

![](assets/delete-location-form.png){.lightbox}

::: {.callout-warning icon="false" collapse="true"}
Note that deleting locations is an irreversible process.
:::

### Mapping locations

For each individual locations, or a group of selected locations using the ![](assets/manage.png){height="30px"} feature, you can visualize the locations on a map within [Data Discover](#sec-data-discover), further gaining insights. Click the ![](assets/dropdown-arrow.png){height="20px"} or right-click the location and select ![](assets/map-menu.png){height="30px"}. A new tab will also visualizing the location in Data Discover.

![](assets/mapping-location.png)

### Location reports {#sec-location-reports}

If you‚Äôre an organization administrator, you can enable **location reports** for individual locations within your organization. This feature allows users to share specific location reports with collaborators without granting full project or organizational access‚Äîideal for sharing information with landowners, leaseholders, partners, or collaborators. To use this feature, navigate to the bottom of the location settings, where you‚Äôll find a "Report Link." Simply copy the link, open it in your browser, or share it with the intended recipient.

![](assets/location-reports.png)

## Location photos {#sec-location-photos}

**Location photos** are photos taken as a means to record the landscape around where a sensor was deployed. WildTrax has the ability to upload, store and manage location photos and attribute basic metadata for them. You can also filter and sort through your photos within the location photos tab.

![](assets/location-photos.png){.lightbox}

### Uploading location photos

Organize your location photos by ensuring each folder on your computer is named to correspond with the specific location where the photos were taken. During the upload process, the system will automatically search within each folder and assign the images to the matching location based on the folder name. Go to the Location photos tab and click on ![](assets/upload-location-photos-button.png){height="30px"}. Each individual location with the files will be in view. When you are ready, click ![](assets/confirm-and-upload.png){height="30px"}

::: {.callout-warning icon="false" collapse="true"}
If the location doesn't exist in the organization yet, you'll have to add it first otherwise you'll get a warning during the upload process. Go to the Location tab and click ![](assets/create-location.png){height="30px"}.

![](assets/location-photo-upload-error.png){.lightbox}
:::

### Adding location photo metadata

Each location photo will also have the following properties that can be assigned to each photo. You can do this for each individual image with the pencil icon below each image, or in batch, by selecting multiple image and then clicking ![](assets/manage.png){height="30px"} then ![](assets/edit-location-photos.png){height="30px"} or ![](assets/delete-location-photos.png){height="30px"} as needed.

-   **Direction**: cardinal direction of the location broken down into sub-cardinal units
-   **Vertical Angle**: angle at which the image was taken relative to cardinal north
-   **Access**: the accessibility of the image; this is also determined by organization administrators (see [Default privacy settings](#sec-default-privacy-settings))
-   **Comments**: any useful information about the image

## Visits

A **visit** is when an observer has gone to a location to collect environmental sensor or biological data. When equipment is placed at a location during a visit, WildTrax calls this a [deployment](#sec-deployments). At each of these times, you can add sensor (i.e., equipment) metadata to support the visit. The goal is to provide ways of standardizing field metadata collection so that it can be easily shared with other organizations or WildTrax users.

*Why are visits important?*

-   Visit metadata provides quality control for environmental sensor media and metadata collected at the location
-   Visits relate field activities on the landscape to equipment, media and biological data
-   Visits record general information about the landscape where the environmental sensor was placed or the biological data collected

*Do I need to collect visit data?*

Visit metadata is not a requirement however you will not be able to upload visit images or equipment metadata without a visit.

*What visit data is supported in WildTrax?*

Two major activities can take place during a visit: using an environmental sensor or conducting a point count. WildTrax currently supports the addition of general landscape information and subsequent deployment information.

### Create visits

To create a visit:

Go to the Visits tab in the organization. Click Create Visit Select or search for the location from the list in the table. The visit summary form will appear, which is a comprehensive list of all visits and equipment for that location. 5. Click on Create Visit.

6.  Enter the visit date in the visit form Click Save after which the visit images tab will appear, and the Add Sensor button will turn green and allow you to begin adding other metadata to the visit. You only need to enter a date in order to create a visit; the rest of the values are optional.

### Sync visits

Just like with locations, you can batch upload and download visits and visit metadata by clicking the Manage button.

Click on Download Visits to get the current list of all visits and metadata in your organization. If you don‚Äôt have any metadata yet, the CSV will provide the column headers. Conduct the edits or changes to your CSV. Click on Upload Visits. This will take you to the Upload CSV form; choose your local CSV file and click Preview Changes‚Äîthis will allow you to preview the changes you‚Äôll be making to your location data. If there are no differences, a prompt indicating ‚ÄùNo changes detected in this file‚Äù will appear. To accept the modifications, scroll down and click Apply Changes. You only need to enter a date in order to create a visit; the rest of the values are optional.

Here‚Äôs a list of the CSV fields and their descriptions that can be included when syncing visits:

Location: the name of the location. Visit date: the date a location was visited (in the format ‚ÄúYYYY-MM-DD‚Äù). Crew: the name(s) of the crew member(s) who visited the location. Bait/lure type: the type of wildlife attractant (e.g., scent, lure, bait, etc.) placed in front of the camera (if applicable). Access method: the method that best describes how the crew accessed the location (e.g., ‚ÄúOn Foot,‚Äù ‚ÄúATV,‚Äù ‚ÄúHelicopter,‚Äù etc.). Walktest distance (m): the horizontal distance from the camera (in metres) at which the crew members perform the walktest (using the walktest mode, if applicable). Walktest height (m): the vertical distance from the camera (in metres) at which the crew members perform the walktest (using the walktest mode, if applicable). Facing human feature: flags used to identify whether a camera is facing a human feature or if an ARU is in the range of a human feature (depending on the sensor type). Visit trigger mode(s): the camera setting that determines how the camera is set to activate (i.e., motion/heat \[‚ÄúTrigger‚Äù\] and/or at set intervals \[Time-lapse‚Äù\]). Motion image interval (seconds): the camera setting which provides the time (in seconds) between images within multi-image sequences that occur due to motion, heat, or activation of external detector devices. If a motion image interval was not set, enter ‚Äú0‚Äù seconds (i.e., instantaneous). Quiet period (seconds): the camera setting which provides the time (in seconds) between trigger events; that is, if the camera was programmed to pause between firing initially and firing a second time. If a quiet period was not set, enter ‚Äú0‚Äù seconds. The quiet period differs from the motion image interval in that the delay occurs between multi-image sequences rather than between the images contained within multi-image sequences (as in the motion image interval). Visit comments: comments describing additional details about the visit.

::: {.callout-tip icon="false" collapse="true"}
Batch upload processes in WildTrax support **add** and **update** operations only; deletions are not allowed. For example, if you accidentally upload an empty CSV, no existing data will be deleted.
:::

### Delete visits

## Equipment {#sec-equipment}

![Equipment tab](assets/equipment-tab.png){.lightbox}

### Add equipment

### Manage equipment

### Sync equipment

::: {.callout-tip icon="false" collapse="true"}
Batch upload processes in WildTrax support **add** and **update** operations only; deletions are not allowed. For example, if you accidentally upload an empty CSV, no existing data will be deleted.
:::

### Delete equipment

## Deployments

![](assets/lots-of-aru.png)

**Deployments** are equipment with their associated location and visit during deployment and / or retrieval from the field. Once locations and visits are created and equipment inventories added to the [Equipment](#sec-equipment) table, users can then take advantage of the Deployments tab to associate the history of what is happening at location or equipment over time.

![](assets/deployments.png){.lightbox}

### Add deployments

Go to the Deployments tab in the Organization and

### Manage deployments

### Sync deployments

::: {.callout-tip icon="false" collapse="true"}
Batch upload processes in WildTrax support **add** and **update** operations only; deletions are not allowed. For example, if you accidentally upload an empty CSV, no existing data will be deleted.
:::

### Delete deployments

## Recordings

![Recordings tab](assets/recordings-tab.png){.lightbox}

### Upload recordings {#sec-upload-recordings}

::: {.callout-important icon="false" collapse="true"}
#### **Important upload restrictions**

- For a stable and secure upload process, it‚Äôs strongly recommended to use an ethernet connection before proceeding. Large uploads can take a while, so start with smaller batches to gauge your upload time, and then proceed with larger batches.
-Supported format are the following. Each recording uploaded to WildTrax is either compressed as a *flac* or kept as an *mp3* if uploaded as such
  - *wac* and *w4v* are proprietary, lossless compressed file formats developed by Wildlife Acoustics
  - *wav* is the standard, ubiquitous uncompressed audio file format
  - *mp3* a lossy compressed audio file format; works by reducing the accuracy of certain sound components, and eliminating others
  - *flac* is a lossless compressed audio file format
- Each recording **must** include a location prefix to be accepted. These are included in [Wildlife Acoustics](https://www.wildlifeacoustics.com/) ARUs but check your make and model type. The **location name** can be changed later (see #sec-locations) if the prefix is incorrect and you do not have a way of changing the name on your local media.
- Each recording must include a date and time in an accepted format (e.g., YYYYMMDD_HHMMSS). Once uploaded, the recording's date and time cannot be modified, so ensure they are accurate before uploading. If errors are found after upload:
  - You must [delete the recording](#sec-delete-recordings).
  - Correct the name or metadata in your local copy.
  - Re-upload the corrected recording.

Please review all details carefully to avoid upload issues.
:::

To upload recordings for storage and processing in WildTrax, navigate to the Recordings tab and then click ![](assets/upload.png){height="30px"} This opens the recording upload window, where you can configure settings before uploading your files.

WildTrax provides several options to optimize your upload process:

-   **Including Subdirectories**: Useful if your media is organized hierarchically.
-   **Removing Leading Zeros**: Uncheck this option to retain leading zeros in location names
-   **Trigger Marking**: Distinguishes triggered recordings from schedule-based ones. See [Setting up an ultrasonic project](#sec-setting-up-ultrasonic)
-   **Pre-Scanning**: Scans for and displays sample rate and recording length during the upload process

![](assets/upload-recordings.png){.lightbox}

To begin, click **Choose a Folder to Upload**, select the directory containing your recordings, and let WildTrax scan the files. Once scanning is complete. Next, optionally enter spatial coordinates for new locations or update missing coordinates. This can also be done later using [location sync](#sec-location-sync). If a location doesn‚Äôt already exist in the organization, WildTrax will create it through the upload process.

![](assets/add-coordinates-upload.png){.lightbox}

Once you've reviewed the queue, click ![](assets/begin-upload.png){height="30px"} to start the upload.

![](assets/upload-queue.png){.lightbox}

You can follow along the the uploads in the interface. After the uploads are complete, you can download and review the Log to ensure that all files were succesfully uploaded.

![](assets/upload-success.png){.ligthbox}

::: {.callout-note icon="false" collapse="true"}
#### What's the difference between uploading recordings to the organization versus the project?

- Uploading to a project uploads both the recordings and generates each recording as a task. The recording is still stored in the organization at its full length even if a task was generated at a shorter length. 
:::

### Acoustic classifiers

An **acoustic classifier** is a computer algorithm designed to analyze audio recordings and identify the species producing the sounds. These classifiers interpret spectrograms, visual representations of sound frequencies over time, to determine the presence of specific bird species or other acoustic taxa. [BirdNET](https://birdnet.cornell.edu/) and [HawkEars](https://www.sciencedirect.com/science/article/pii/S1574954125001311) are two examples of such classifiers used by WildTrax, trained to process audio recordings and classify the species captured within them. For each recording uploaded to WildTrax, BirdNET and HawkEars are automatically run on the recording, and the results are made available in the **Recordings** tab, allowing users to view or further process the recordings in a project. Similarly, when recordings are [uploaded directly through a project](#sec-uploading-recordings-and-tasks), the [classifier overlays](#sec-acoustic-classifier-overlays) are accessible in the processing interface. The algorithms behind these classifiers differ, which can result in varying levels of accuracy depending on the species and recording conditions, performing differently in specific situations.

![](assets/recordings-with-species.png){.lightbox}

-   **BirdNET** ![](assets/birdnet.png){height="30px"} is a worldwide bioacoustic classifier, which has been trained to classify thousands of species
-   **HawkEars** ![](assets/hawkears.png){height="30px"} is a regional classifier that has been trained to classify hundreds of species, mostly Canadian and northern US species

BirdNET and HawkEars analyze 3-second *windows* (i.e. periods of time) of the [spectrograms](#sec-acoustic-data-concepts), providing confidence scores from 0 to 1 for each species in their model. In other words, a score of 0.9 is more likely a hit of an American Robin than a score of 0.2.

::: {.callout-tip collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
See [Wood and Kahl](https://link.springer.com/article/10.1007/s10336-024-02144-5) for more information on score thresholds.
:::

### Filter recordings

![Filter panel](assets/filter-recordings.png){.lightbox}

![](assets/filter-recordings-form.png){.lightbox}

### Generate tasks

![](assets/generate-tasks.png){.lightbox}

### Delete recordings

![](assets/multiselect-options.png){.lightbox}

## Image sets

You can access image set metadata from the image sets tab. Note that this information differs in the project‚Äôs image sets tab.

![Image sets tab](assets/image-sets-tab.png){.lightbox}

Here you will find summaries of the following information:

-   **Location**: the name of the location
-   **Image set start date/time**: the date and time of the first image collected in the image set (in the format YYYY-MM-DD HH:MM:SS)
-   **Total image count**: the total number of images Motion image count: the total number of images where the camera was triggered due to heat or motion (i.e., Trigger mode = ‚ÄúMotion Detection‚Äù or ‚ÄúM‚Äù) in an image set Task count: the total number of tasks Details drop-down: clicking on the drop-down arrow will show the projects the image set is associated with, the observer who tagged the task, the number of unique species detected, and the series gap used in the project.

## DOIs

<mark>Within the DOIs tab, users can create DOIs via [DataCite](https://datacite.org/) that allows users to create DOIs links for their projects. There are certain restrictions and conditions for creating and using DOIs:</mark>

-   You must at least an Organization administrator to create DOIs for the underlying projects
-   DOIs can only be created for projects belonging to the Organization
-   When a project is deleted or merged, the DOI ...

![](assets/dois-tab.png){.lightbox}

### Creating a DOI

Click on the DOIs tab in the Organization and then click ![](assets/create-doi-button.png){height="30px"}. The form will then appear allowing you to give a **Title** and select which **Projects** will belong to the DOI.

![](assets/create-doi.png){.lightbox}

### Deleting a DOI

For any DOI in the menu, right-click or select through the ![](assets/dropdown-arrow.png){height="30px"} the ![](assets/delete-doi.png) option. You can also delete multiple DOIs by selecting multiple DOIs and going to ![](assets/manage.png){height="30px"}. You'll be prompted to go through the process of confirming the deletion prior to it taking place.

![](assets/delete-dois-form.png){.lightbox}

# ARU Projects üéß {#sec-aru-projects}

**Projects** are purposeful groupings of an organization‚Äòs media and metadata to answer specific questions or implement a study design. Projects can be one of three sensors: ARUs, cameras or point counts. For each of these sensor types, a collection of tasks (ARU), image sets (camera) or surveys (point counts) are processed or uploaded in order retrieve species data.

The goal of an ARU project is to upload media, process tasks, verify tags and publish the results. Projects belong to organizations and use organization media on order to generate and report on a certain set of results designed by the project administrators. Clicking on the ARU sensor on the main project dashboard will show which projects you have access to. The list of projects you see is determined by your organization membership, project membership and status of the project. You can use the filter and sort some of the project attributes to find what you‚Äôre looking for:

![](assets/aru-projects.png){.lightbox}

::: {.callout-note collapse="true" style="background-color: #f4f4f4; padding: 20px;"}
This section pertains to managing ARU projects. If you are looking to create or manage [camera]() or [point count data](), jump to the appropriate sections.
:::

## Acoustic data concepts {#sec-acoustic-data-concepts}

Acoustic recordings are made by sampling sound pressure waves from the environment. Sampling rate (the number of samples taken per second) and bit depth (degree of quantization of pressure measurements) are two important values to consider when making sound recordings. Waveforms or the shape of the total acoustic signal over time are difficult to interpret.

These waveforms can be transformed into spectrograms. This is done using algorithms called Fourier transformations to make acoustic data more intelligible to a human or other software. These spectrograms contain patterns that a human can more easily use to recognize an acoustic signal and convert into biological data, such as animal vocalizations.

A spectrogram is a visual representation of the acoustic energy in a recording created using a short-time Fourier transform (STFT). The x-axis corresponds to time, the y-axis to frequency and the z-axis (or how dark the signal is) to amplitude. Spectrograms in WildTrax are generated with a command line software called SoX. Audio file types have been calibrated to create the ‚Äúbest looking‚Äù spectrograms.

Animals use acoustic signals to communicate messages for mate attraction, territorial defense, identification, or alarm. Acoustic signals are important metrics that biologists and scientists can use to study animal populations, community assemblages, or individual fitness. Collecting sound signals also provides a permanent, unbiased, analyzable, and reproducible dataset for researchers in contrast to point count data.

An ARU can be deployed at a location for a long period of time. This provides a number of benefits to users processing acoustic data and project administrators to optimize their study design. If you‚Äôre just getting started using ARUs, WildTrax‚Äôs recommendations on how to best process acoustic data are based on the analyses, reports and publications that can be found in the Resources section.

How long you leave an ARU out at a location and how much data you process depends on your objective. Thus, there is no one answer that optimizes results for all species or for all questions. The inclusion of groups such as amphibians, owls, or nocturnal species changes the optimal ways of sampling with ARUs. For songbirds, there is strong evidence that shorter duration surveys (e.g., 1 minute) will increase detection rates and allow for a greater number of recordings from different days to be processed. This will result in more species found faster. However, trade-offs with other methodological approaches will occur. For example, 1 minute methods have higher detection error per visit but cumulatively have higher detection overall if you put in equal effort (10 x 1-minute point counts vs. 1 x 10 minute point counts). More work is needed to understand the implications of using occupancy estimates from short versus longer periods of sampling time per individual point counts in terms of the stability of occupancy estimates. There are no firm recommendations on whether the total time should be 3, 5, or 10 minutes, etc. per recording processed. However, we do strongly recommend that listening in 1-minute time blocks within any longer interval provides the greatest flexibility in methods and highest return on processing investment. The ability to estimate parameters such as song rate with USPM methods increases the utility of such data and has the potential to help better measure a greater array of state variables (e.g., singing rate, occurrence or density). A single day of recording does not seem to be the best way to estimate occupancy or assess probability of occurrence. Leaving an ARU to record at a location for several days seems to provide a reasonable balance in getting detections from species that hold territories close to an ARU while also increasing the probability of getting rarer species with larger home ranges that only periodically are near an ARU. Less is gained by leaving them out for a month if it comes at the cost of visiting more locations.

## Acoustic project management

The goal of an ARU project is to upload media, process tasks, verify tags and publish the results. Projects belong to organizations and use organization media on order to generate and report on a certain set of results designed by the project administrators.

Clicking on the ARU sensor on the main project dashboard will show which projects you have access to. The list of projects you see is determined by your organization membership, project membership and status of the project. You can use the filter and sort some of the project attributes to find what you‚Äôre looking for:

### Create an ARU project

Click on Create an ARU Project. This will open the Project Settings form allowing you to begin adding information to the project. The Create/Update ARU Project contains the following fields; those marked with an * are mandatory before being able to create the project:

Project: A short name to identify the project.
Organization*: Drop-down list of all existing organizations of which you are an admin. This field allows you to group all of your projects together in the database. Once your project is saved, you will be unable to change the organization to which it belongs.
Data Source: A field used to specify the original source of the data; this field should be entered if you are importing data from an outside source (e.g., previously tagged data).
Purpose and methods: A short description of the methods used to create this project and goals it hopes to achieve.
Results summary: A short description of the results your project found.
ARU project options box:
Default minimum frequency (Hz) and default maximum frequency (Hz) of the spectrogram that will be displayed
Default X-Scale: Length displayed in seconds. Corresponds roughly to 0.25x (60 seconds) to 10x (2 seconds) in length displayed
Default Y-pixels: Height of the spectrogram in pixels 
Default monochrome: Default to monochrome colour palette toggle. Alternative is colour
Default light mode: Default to light mode toggle; alternative is darkmode spectrograms

### Species assignment

The Assign Species tab contains a set of tools that allow you to limit or choose which species you want to tag in your project. You may want to do this in order to control the amount of tagging error (incorrect species identification) or to limit which species you want to tag.

To add species to your project, click on a species in the Not Included column (the row will turn blue once selected) and click the arrows to add it to the project‚Äôs Included list. You can also unselect and select all from either column. Once a species has been tagged in the project, the assign species tab will automatically lock the row preventing you from removing the species from the project if it has already been tagged.

You can also add an entire group of species using the preset groups found in the Apply Preset button. Click Apply Preset and then search and select which groups of species you‚Äôd like to use. You can select one or many groups at a time. Once you‚Äôre done with your selection, click Submit and the species will be added to the project.

If you have a preset group or species you would like to be available, email info@wildtrax.ca with a request.

### User assignment {#sec-aru-project-users}

Once you‚Äôve created and saved your project details, you‚Äôll be able to manage the users who are part of the project. Select the tab to add and view current administrator and read-only project members.

Project administrators have both read and write access to the project details, settings. They can add users to the project and can assign taggers to tasks.

Project read access members can view project details, and settings, and all tasks within the project. However, they can only edit tasks assigned to them.

Once you have created your project and close the window, the new project will be visible in the ARU project list. Click on the project title to enter the project page or click on the pencil icon to edit project details, settings or users.

Users are granted their respective membership levels to an organization‚Äôs projects. You don‚Äôt need to add an organization member to a project unless you need to grant them administrator privileges and they only have organization read-only.

### Uploading recordings and creating tasks {#sec-upload-recordings-tasks}

In order to process data, a task must be generated and assigned in WildTrax. A task is a unique combination of an acoustic recording, a processing method, and an observer. The observer needs to be at least a read-only project member and assigned the recording in order to process it. WildTrax has the ability to process acoustic recordings with multiple methods and users, however, please contact WildTrax Support to provide this service.

To upload recordings for processing, navigate to the Recordings tab and then click ![](assets/upload.png){height="30px"} This opens the recording upload window, where you can configure settings before uploading your files.

WildTrax provides several options to optimize your upload process:

-   **Including Subdirectories**: Useful if your media is organized hierarchically.
-   **Removing Leading Zeros**: Standardizes location naming to a generic WildTrax format (optional but recommended).
-   **Automatic Task Generation**: Recordings uploaded through a project automatically generate tasks, enabling spectrogram creation and dashboard integration.
-   **Trigger Marking**: Distinguishes triggered recordings from schedule-based ones.
-   **Pre-Scanning**: Displays sample rate and length during the upload process for better oversight.

To begin, click **Choose a Folder to Upload**, select the directory containing your recordings, and let WildTrax scan the files. Once scanning is complete, you can proceed to the next step.

In the next step, optionally enter spatial coordinates for new locations or update missing coordinates. This can also be done later using the Upload and Download Location tool. Key points to note:

-   If a location doesn‚Äôt exist in the organization, WildTrax will create it.
-   Recordings shorter than the specified method length by more than 3 seconds will trigger an error (e.g., a 56-second recording for a 60-second method).

Once you've reviewed the form, click **Upload Files in Queue** to start the upload. For a stable and secure upload process, it‚Äôs strongly recommended to use an ethernet connection.

When recordings are uploaded to a project, new tasks are generated from the media and are added to the project dashboard under My Tasks.

A task is a unique combination of a user, a processing method and a recording. This flexibility allows you to generate tasks using the same recording but allow for multiple users or processing methods.

Go to the project dashboard and click My Tasks. The form will display the list of tasks currently in view depending on the View only my tasks toggle‚Äîswitching the toggle to red allows you to filter the list to only your assigned tasks. The metadata for each one includes the location name, the date and time of the recording, the method it was assigned, the status of the task and the assigned user.


### Syncing data to ARU projects

You can sync locations, tasks and tags via an ARU project. This allows you to make changes across many locations, tasks or tags as needed throughout the processing workflow. You may need to use sync to make large changes to location names or visibility settings, edit who is assigned tasks, or change metadata related to species tags. The logic of sync lies in downloading the data from a project (or a template with column headers if there is no data in the project yet).

::: {.callout-tip icon="false" collapse="true"}
Batch upload processes in WildTrax support **add** and **update** operations only; deletions are not allowed. For example, if you accidentally upload an empty CSV, no existing data will be deleted.
:::

Administrators can benefit from managing only the locations from the media in the project, This differs from location management at the organization level, where locations from all projects can be managed.

Click the Manage button and go to Download Location CSV to obtain the current list of locations in the project. If you don‚Äôt have any locations yet, a template will be provided.
Make the changes or additions you‚Äôd like in the csv and re-upload the csv with the modifications using Upload Location CSV

If you didn‚Äôt generate tasks when you uploaded recordings to the project, or, if you‚Äôre using an organization‚Äôs recordings to create tasks, you can also use the Upload Tasks tool under the Manage button to automatically generate the tasks you need. Use the Download Tasks or Download CSV Template button and fill in the following fields:

Location: The name of the location.
Recording date/time: The date and time that a ARU recording was collected (in the format ‚ÄúYYYY-MM-DD HH:MM:SS‚Äù).
Task method: The method used to process the recording (SPM = 1 tag per individual per species per minute, SPT = 1 tag per individual per species per task, NONE = other methods).
Task duration (seconds): The duration the recording was processed during the task or the duration of the point count.
Observer ID: The unique numeric primary key of the observer that processed the image or recording, or that conducted the point count.
ARU task status: The processing state of the ARU project task (recording) (i.e., ‚ÄúNew,‚Äù ‚ÄúIn progress,‚Äù ‚ÄúTranscribed,‚Äù ‚ÄòBad weather,‚Äù or ‚ÄúMalfunction‚Äù).
Rain: The average rain on the task
Wind: The average wind on the task
Industry noise: The average chronic industrial noise on the task
Other noise: Other noise averages on the task
Audio quality: The audio quality of the task (recording).
If you have hundreds or thousands of tasks without an assigned user, you can use the Randomly Assign button and select users from the dropdown list on the left to assign tasks to. It will randomly, and equally, assign unassigned tasks to the selected user(s).

If you‚Äôre a project administrator, you can also delete tasks from the project dashboard by clicking the drop-down arrow beside the desired task and clicking Delete Task. Follow the prompts and warnings accordingly as task deletion is permanent and irreversible.

The ‚ÄúManage‚Äù button also contains functions that allow you to to upload and download tags to and from a project. This is useful if you‚Äôve ever tagged acoustic data in another database and wish to sync it to WildTrax standard or you‚Äôre looking for a downloadable record of the tags and their metadata. Here are the CSV fields required in order to upload; if your project doesn‚Äôt contain any tags, you‚Äôll be able to download a template first by clicking ‚ÄúManage‚Äù.

Before you can upload tags into the system, you‚Äôll need to first upload the recordings and create tasks in order to have the proper metadata needed to populate the tag CSVs. You cannot generate tags for tasks or recordings that don‚Äôt exist.

Location: The name of the location
Recording date/time: The date and time that an ARU recording was collected (in the format YYYY-MM-DD HH:MM:SS)
Task method: The method used to process the recording (SPM = 1 tag per individual per species per minute, SPT = 1 tag per individual per species per task, NONE = other methods).
Observer ID: The unique numeric primary key of the observer that processed the image or recording, or that conducted the point count.
Species common name: The common name of the species that was observed in the tag or point count.
Individual: This field corresponds to uniquely identified individuals of a species on the recording. In other words, if you hear two Ovenbirds (OVEN), the first individual would be tagged as ‚Äú1‚Äù and the second OVEN as ‚Äú2‚Äù. WildTrax has been designed to automatically populate the Individual field as new data is being entered. Therefore, if you forget to add in the individual number, the system will update it for you automatically in sequence.
Vocalization: The vocalization type of the tag (i.e., ‚ÄúSong,‚Äù ‚ÄúCall,‚Äù or ‚ÄúNon-vocal signal‚Äù).
Start time (seconds): The start time(s) of the window of the recording processed by the classifier.
Tag duration (seconds): The duration of the tag (in seconds).
Minimum frequency (Hz): The minimum frequency (in Hertz) of the tag.
Maximum frequency (Hz): The maximum frequency (in Hertz) of the tag.

Click on the Manage button and select Upload Tags. In the new pop-up window, select Choose a CSV file to upload to select your tag data. When the file is uploaded, the ‚ÄúQA Tag Data‚Äù button will turn green. Click it and WildTrax will ensure that the data you‚Äôre uploading fits the WildTrax standard. This may take a few minutes depending how large your file is.


::: {.callout-warning icon="false" collapse="true"}
You may be running a classifier outside of WildTrax on your raw media, wishing to sync the classifier hits as tags within a project. Note that some classifiers use windows of data, and syncing these as tags should be proceed with caution. Your best bet when syncing classifier hits is simply to note the start_time of the t
:::

### Setting up an ultrasonic project ü¶á {#sec-setting-up-ultrasonic}

There are some specific steps needed in order to setup a project appropriate for ultrasonic data. Note that the majority of WildTrax's

#### Uploading recordings

Under the My Projects tab you can find your project and manage it to upload recordings.

::: {.callout-warning icon="false" collapse="true"}
Currently WildTrax does not accept zero-cross files then you will need to upload them as other files into your project.
:::

#### Syncing classifier tags

WildTrax supports ultrasonic data syncing bIf you have ran your data through an recognizer like Kaleidoscope AutoID you can upload the tags onto wildtrax using the wildrtrax package. Download the wildrtrax package and install it into R Use the function wt_kaleidescope_tags to make Wildtrax tags from the Kaleidoscope output Once you have a csv with your Wildtrax tags, go to your project in Wildtrax and click the Manage button and select Upload Tags Select the appropriate csv, click on Check Tag Data This will do a quick QA/QC to ensure that all the tags that are being uploaded are associated with a correct recording If there are no errors with the data and click on Upload Tags

::: {.callout-tip icon="false" collapse="true"}
Batch upload processes in WildTrax support **add** and **update** operations only; deletions are not allowed. For example, if you accidentally upload an empty CSV, no existing data will be deleted.
:::

### Downloading reports and media



### Merge projects

You may need to use environmental sensors across a number of years or for specific questions related to study design. WildTrax offers an unlimited number of projects that can be created at any time in order to cater to this need. However, there are times when these questions and multi-year projects can be unified to collate and make the data more cohesive. WildTrax gives you this ability with the project merging tool.
Clicking on the drop-down arrow beside the project name on the dashboard will also show the Merge Project button. This function allows you to merge a source project to a target project.

### Delete a project

### Publishing a project

Go to the pencil icon or right-click on the project within the dashboard. Go to Status and change the project status. Note that publishing the project will lock it to taggers, read-only members, etc. Choose your publication status wisely (see #sec-publishing-and-sharing)

## Acoustic tagging

This section is designed to provide a comprehensive overview of the tools and features available within the acoustic tagging page. Jump ahead to the section on methods if you‚Äôre looking for more details on tagging methods for species identification.

![](assets/aru-processing.png){.lightbox}

### Controls and settings

Audio editing controls have been implemented in WildTrax using hotkeys allowing easy navigation through a task. Hovering over the panel above the spectrogram will remind you how to use these controls at any time if you forget.

Z: Jump back 10 seconds
M: Jump forward 10 seconds
B: Toggle display for boxes
T: Toggle display for species | individual text
L: Show / hide tags on the left channel
R: Show / hide tags on the right channel
Left Arrow: Previous marker
Right Arrow: Next marker
Up Arrow: Go to the first marker
Down Arrow: Go to the last marker
Spacebar: Pause / Play
Tab: Move between fields
1: Create a marker
Enter: Select within a field

You can dynamically set the audio settings which control the spectrogram and audio parameters of the recording for the task. These settings are set by default at the project level by an administrator but you can change them at any time while processing a task. You can set the audio settings by either clicking on the gear icon below the spectrogram or going to Manage > Audio Settings above and to the right of the spectrogram. When you have your desired settings, click Apply or Reset to the project defaults.

Channel: Set the default channel that will display on the screen (left, right or both)
Amplify: Increase the gain or amplitude of the audio to hear faint sounds
Minimum and Maximum Frequency (Hz): The minimum and maximum bounds displayed on the spectrogram. The audio will be played for the entire spectrum unless the Generate Audio toggle is enabled.
X-Scale: Use the slider to change the amount of seconds displayed on the spectrogram. A lower value will display more time whereas a larger value will display less time.
Y-Height: The spectrogram height in pixels. A larger number will increase the vertical dimension of the spectrogram
Use Monochrome: When toggled on, displays spectrogram in a monochrome format (black and white). Toggle off to display colour spectrogram.s
Generate Audio: When toggled on, only the audio between the selected frequency ranges will be played.
Noise Filter: Attempts to apply a noise filter to better help hear the signal.
Contrast: Contrast range in dB. Default is 120 dB. This sets the dynamic-range of the spectrogram to be the selected value dBFS to 0 dBFS. This may range from 20 to 180 dBFS. Decreasing dynamic-range effectively increases the ‚Äòcontrast‚Äô of the spectrogram display, and vice versa.
Brightness: Sets the upper limit of the Z-axis in dBFS. A negative number effectively increases the ‚Äòbrightness‚Äô of the spectrogram display, and vice versa.

### Noise, weather and malfunctions üå¨Ô∏è üåßÔ∏è

ARUs don‚Äôt discriminate between noise sources, including geophonic (e.g., wind and rain) and anthropogenic (e.g., human produced) sounds. Assessing, tagging, and recording these noise sources is important as they can affect species detection depending on the frequency range and amplitude of the abiotic signal.

For example, certain recorders can be placed very close to industrial features such as compressor stations where noise is almost constant throughout the entire recording due to motors, fans, engines, etc. Others can be located near busy roads where cars may pass by. All these sounds have distinct acoustic signatures that can be identified and tagged on a spectrogram. Noise sources can also be biotic such as bugs flying past the microphones. 

Keep in mind that the assessment of noise can be made both through frequency and/or amplitude. Even faint broad-scale sounds will affect species detection, whereas a loud low-frequency sound can also trick the ear into missing biotic signals.

All ARUs produce a certain amount of internal static; you can record the static to indicate a possible equipment failure. Older models of ARUs have a lower signal-to-noise ratio that can produce the increase in static.

As wind, rain, and industrial noise increase in intensity and frequency, biotic sounds are harder to detect and accuracy with species identification decreases. You can avoid processing certain tasks where wind, rain, background, or industrial noise is above a certain threshold defined by the project.

You can quickly check if the task will be appropriate for conducting an analysis based on the noted noise threshold. Sometimes this can be very easy (e.g.. recording will have obvious heavy rain). Other times you may need to scroll quickly through the recording to check. You can either proceed with the transcription or change the status of the task to Bad Weather and move onto the next task.


The weather panel also provides a way of making assessments of the weather conditions to determine whether or not they are appropriate for processing. WildTrax will develop recommendations for this in the near future. 

Conditions recorded at the nearest weather station (at the nearest time to when the ARU recording took place) are located in the panel just above the spectrogram. Clicking on the panel opens the detailed weather information panel describing both hourly and daily conditions recorded at weather stations within a maximum radius of 155 km. You can toggle through the list of stations with the Previous and Next buttons to get the conditions recorded at various stations. 

### Map and location photos

If the location of the task you‚Äôre working on contains spatial metadata and/or photos were taken during the visit, the Map and Location Photos tabs will automatically appear next to the Audit tab. This allows you to know where the task took place and what the habitat looked like to help with your species identifications. The Location Photos tab will sort the images by visit date so if you took photos in the winter and summer you can see on the ground how your location changes over the season! 

### Acoustic tagging methods

The acoustic processing methods in WildTrax are designed to emulate avian point counts and are an amalgamation of recommendations provided by the Bioacoustic Unit, the Boreal Avian Modelling project, and Environment and Climate Change Canada based on standard methodologies. 

The processing method is chosen either during the upload stage of the media or by uploading tasks to a project and is based on two values: the processing length of the recording and the ‚Äúcount-removal‚Äù method type.

The first component is the length of time in seconds. The easiest way to think of count-removal is when you tag an individual of a species and then want to ‚Äúremove it‚Äù from the rest of tagging. WildTrax will automatically implement this limit depending on the method you choose. Here we define the limit at the individual level, like OVEN 1 and OVEN 2. There are currently options for a tag per minute limit (1SPM), a tag per task limit (1SPT) or an unlimited number of tags (None). 

Contact WildTrax Support if you would like an additional method added.

### Tags

You can add tags (click and drag a box) or markers (Hotkey: 1) on spectrograms.

The boxes that comprise the tag are the fundamental way that WildTrax differs from many other audio tagging systems: they allow you to enclose a species detection in real-time while providing information about vocalization frequency, length and amplitude using the dimensions of the box. When a box is drawn on the spectrogram, WildTrax requires you to enter species metadata after it is created, which pauses the recording while the metadata is being added.

In contrast, you can use markers to indicate where a signal is detected without stopping the playback. You‚Äôll still need to return later to each marker, draw a box, and enter the appropriate species metadata but this way you can rapidly annotate the vocalizations you want. WildTrax offers these two different ways to tag species to allow you to create your own workflow for data processing. 

When a signal is detected, click and drag on the spectrogram to create a box. Draw the box around the outside of the signal. Depending on your study design, you may want to include harmonic frequencies. Once you‚Äôve drawn the box, the Add New Tag window will pop up on the right side of the spectrogram. 

There are a minimum set of rules that WildTrax uses to create tags. As the system develops, new rules may be applied in the future. Project administrators are invited to instruct their members to annotate species as necessary for the objectives of the project.

Tags are a minimum of 0.1 seconds and a maximum of 20 seconds long as defined by the constraints of the maximum dimensions of the spectrogram currently employed in WildTrax
Tags will always have a minimum frequency of 0 Hz and a maximum frequency of 12,000 Hz as defined by the constraints of the maximum dimensions of the spectrogram
Regardless of spectral coverage, a tag must always have minimum dimensions of 0.1 seconds and 200 Hz otherwise the tag will automatically disappear (in reality the tag must have a minimum size of 5 x 5 pixels)
Depending on what method is applied to the task, the number of tags per species-individual you can make may be restricted

The tag should enclose the whole signal
The tag should be as ‚Äútight‚Äù as possible around the signal leaving as little space as possible
The tag should capture important vocalization patterns and repetitions

The fields associated with each tag are as follows:

Species: This field is a dropdown that operates through detecting text either by a modified version of the American Ornithology code system or the English common name of the species. 
Individual: This field corresponds to uniquely identified individuals of a species on the recording. In other words, if you hear two Ovenbirds (OVEN), the first individual would be tagged as ‚Äú1‚Äù and the second OVEN as ‚Äú2‚Äù. WildTrax has been designed to automatically populate the Individual field as new data is being entered. Therefore, if you forget to add in the individual number, the system will update it for you automatically in sequence.
Needs Review: This checkbox flags tags for expedited verification or if you‚Äôre not confident in the identification of the species or the tag metadata.
Abundance: This field stores abundance information for each detection. It is broken down into two main categories: for amphibian calling intensity(CI) and all other species (1-10 and TMTT).
Vocalization Type: This field describes the type of vocalization each detected species/individual made. Vocalization type can be changed for each individual in each minute interval as well. The current options are song, call and non-vocal. 
Comments: Use this field liberally to make notes about any of the songs or calls relating to the species in question, especially in the case of unknowns.
At any time during tagging you can edit the information stored for each tag either by clicking on the box, or visiting the logged sounds table. Once you click on the box, you can change the dimensions, position or the metadata for any of the fields when the tag panel is open. You can even change the species code of the tag in case it was, for example, accidentally misidentified or you wanted to change it to an unknown. You can also delete the tag altogether.

Every time a tag is made, the information is saved below the spectrogram in the logged sounds table. This is a running list of all of the detections that are currently in the task. The table lets you keep track of the species and individuals that are already tagged and provides another place to edit tags.

Components of the table include the species code, the minute intervals where the species was detected (where applicable depending on method), the abundance, the vocalization type of the species (shaded in different colours to allow ease of visualization) and the confidence of the identification. If you hover over a coloured cell, you can also see the second within the minute interval that the box was created, and by clicking on the cell, WildTrax will transport you directly to the part of the spectrogram where the species was detected and play the recording (if Auto play mode is selected).

This will also open the Tag panel. Clicking on the drop-down arrow beside the Confidence field will also let you navigate back to the species detection and make edits in the Tag panel. The switch just below the spectrogram allows you to toggle auto-playing the recording when you navigate to a tag. 

### Avian individuals and abundance üê¶

Each tag in WildTrax records the individual number and abundance. These fields seem similar but are quite different, and how you use them to tag your data is dependent on your research objectives. Check with your project administrator on how to tag species on your assigned tasks. 

An individual is the unique identifier for distinct individuals of a species. Here‚Äôs an example of a Tennessee Warbler (TEWA) that receives an individual number of 1 (since it is the first) and an abundance of 1 (since it is one individual).

If required by your project, it‚Äôs important to ensure individuals are tracked consistently through each interval of the processing method. This way all individuals are annotated correctly.

The number of individuals you can distinguish and track is dependent on multiple factors and these can either facilitate or hinder your ability. Accuracy in individual tagging increases when:

individuals are territorial (separated spatially)
individuals are sedentary (not moving or not appearing to move via spectrogram attributes such as amplitude or channel)
individuals have unique song attributes or singing behaviour
the species richness on the recording is low (there are no masking signals)
abiotic signals on the recording are low (there is no noise interference)

It becomes difficult to tag distinct individuals when certain species have life history traits or behaviour leading them to be abundant. Alternatively, you can tag multiple individuals of a species at once and change the abundance value to reflect the count of individuals of that species in the tag. You can also use the TMTT (too many to tag) option to indicate an uncountable number of individuals of the species within the bounds of the tag.

Increasing the abundance value should only be used when you‚Äôre certain you can‚Äôt tell individuals apart. If you‚Äôre unsure, it‚Äôs recommended to always use the more conservative estimate. Practicing also helps!

### Amphibian abundance üê∏

During the breeding season, amphibians congregate together making individual counts difficult. Therefore, WildTrax uses a calling intensity (CI) rank as a common measure of estimating amphibian abundance rather than by distinguishing individuals, like with birds or mammals. Call intensity is used as a metric for relative abundance and is adapted from the North American Amphibian Monitoring Program (NAAMP) Amphibian Calling Index (ACI) (2005).

CI 1: Individuals can be counted, there is space between the calls
CI 2: Calls of individuals can be distinguished but there is overlap
CI 3: Full chorus, calls are constant, continuous and overlapping

### Confidence and classifying unknowns

There are degrees of uncertainty in identifying acoustic signals on a recording. Since vocalizing species make a variety of different sounds, the ability of an observer to identify many hundreds of species and all their vocalization types is learned over time. Checking the Needs Review box helps to filter tags for verification. 

When you come across a signal you don‚Äôt recognize, you can either classify it as Needs Review and/or as unknown. It‚Äôs important that these unknowns are incorporated into the dataset accordingly to define that:

The signal is clear but it cannot be identified
The signal is too degraded, faint or masked
The signal is a non-descript short call note or alarm call
As unknowns are detected they should be placed into sub-categories as much as possible to refine how another observer or project administrator will identify it later on. For example, a triller should be identified as UNTL instead of UNPA (unknown passerine) or UNKN (unknown). Be conservative in the categorization process‚Äîif you‚Äôre not sure, always revert to the more basal category, like UNKN. Some signals are too faint, degraded or masked, that they‚Äôre likely not identifiable. The threshold of signal identification is dependent on many factors including amplitude, signal complexity, observer skill, and how much the signal is masked or overlapped by others in the recording. There are certain species complexes that cross over families and genera of species‚Äîin this case the more conservative unknown code should be used.

Faint, generic, and indistinct call notes tend to be overlooked when conducting community census tagging as they do not provide much information to the occupancy or detectability of that individual over time; the BU uses standardized replication at each station to account for these tendencies.

Once a tag is labeled as Needs Review, the panel in species verification will also change to yellow. See species verification for more details.

### Vocalization types

Animals can produce many different vocalizations. In the current version of WildTrax, vocalizations are categorized as either song, call or non-vocal and for ultrasonic species call+feeding buzz.

Song is loosely defined as the male, territorial, mate-attracting vocalization produced by passerine (songbird) males and some non-passerine species. In many bird studies, passerine song is used to estimate the density and population size of a species and is a reliable metric. This is because a male passerine generally sings in the territory it‚Äôs occupying.

Ovenbird (Seiurus aurocapillus) song
Black-throated Green Warbler (Setophaga virens) multiple song types
Calls are any vocalization made by individuals where the sex cannot be distinguished and/or the vocalization is not for mate attraction. Some examples of this include the simpler and less melodious vocalizations typical of some non-passerines as well as vocalizations like alarm calls, begging calls, etc.

Exceptions can and do exist in the natural world. For example, despite being passerines, all corvid vocalizations are calls, as both males and females can produce them. Conversely, the Yellow Rail (YERA) is a non-passerine but the primary vocalization (‚Äútik-tik tik-tik-tik‚Äù) is always entered as a song since it is for territorial delineation and mate attraction, and the female does not produce the vocalization.

Flight calls are other unique vocalizations given by birds that WildTrax differentiates as they come from trigger-based recordings and separate study designs from scheduled-based recordings. It‚Äôs possible with certain families like the thrushes (Turdidae) and blackbirds (Icteridae) to identify these call signals to species.

Night flight call notes
White-throated Sparrow (Zonotrichia leucophrys) call notes
Swainson‚Äôs Thrush (Catharus ustulatus) call notes

Non-vocal vocalizations are mechanical sounds made by a species, such as winnows, bleats, drums or booms that are not made by the vocal tract.

Wilson‚Äôs Snipe (Gallinago delicata) winnowing
Yellow-bellied Sapsucker (Sphyrapicus varius) drumming
Call+Feeding Buzz are the rapid series of calls produced to capture prey by echolocating species.

Little Brown Bat (Myotis lucifugus) feeding buzz

Depending on the taxa that you‚Äôre studying, you may want to use these categories differently than how WildTrax suggests. These recommendations, while imperfect, reflect common practices and help to standardize vocalization metadata. Nevertheless, the system is agnostic to vocalization type standards and is a proponent in making the system as flexible as possible. If you have a recommendation or suggestion on how to help develop this standard, email WildTrax Info.

### Ultrasonic species ü¶á

### Acoustic classifier overlays {#sec-acoustic-classifier-overlays}

If enabled in the project, each processing tasks includes the ability to overlay acoustic classifier detections. Within WildTrax, the goal is to help promote

### Species verification

The species verification tab houses a set of tools to assist in the quality control of acoustic tags. In species verification, administrators assign users as validators to verify all tags grouped from a species-vocalization type in a project. Species-vocalization type is used for the grouping to allow the user to focus on one signal type at a time, e.g., Wilson‚Äôs Snipe (WISN) calling vs. winnowing. Species verification is important because it allows you to efficiently check all the tags produced in a project before publishing it, thereby dramatically increasing data quality output. 

ARU species verification in WildTrax is a two-stage approach:

1) Create or import tags in a project

2) Verify all the tags of a species-vocalization type

This allows a WildTrax user to have the first pass at processing the acoustic data and then use the verification tools to target and verify tags. Verification tags are populated once the task is completed (or switched to Transcribed). Clicking on the Species tab in the project page displays a list of species-vocalization types, summaries of the total number of verified tags, and tools to assign users for verification, in order to help you manage the verification process. Click on any of the species to enter the verification page.

This is the standard practice currently used in WildTrax. Use this route if you have trained taggers who will be generating tags from assigned tasks.

Upload recordings to a project and generate tasks by checking Create a new task
Assign users as taggers to the tasks
Tag all of the tasks in a project
Assign validators under the Species tab
Verify all of the tags for each species-vocalization type where desired; return to the tasks to change or delete tags where needed
Filter by verified tags and mark high quality ones as Nice, or mark as Nice as you verify
Proceed to publishing your verified project

If you have outputs from a recognizer and wish to verify the hits and share the results in WildTrax:

Upload recordings to a project and create tasks
Upload tags from the automated classifier
Assign validators under the Species tab
Verify all of the tags for each species-vocalization type where desired; return to the tasks to change or delete tags where needed
Rate the tags to help determine recognizer performance
Proceed to publishing your verified project

The verification page header designates the species-vocalization type you‚Äôre verifying and the filters are metadata you can use to filter the list of tags you see in the single tag panels. The single tag panels allow you to individually access and manipulate the audio and spectrogram properties, and take actions in order to verify the tag.

You can listen to any of the audio in the single tag panels by clicking the Play button  in the top-left hand corner. The icons below the spectrogram indicate the following:

Verify: when checked green , the tag has been verified. The background of the single tag panel will also change to green. 
Rating : when checked yellow , the tag has been rated
Task link : opens a new tab to the task where the tag was created; the tag will be coloured black in the task
BirdNET probability: maximum probability (0-1) returned from BirdNET. The number is the maximum value found in all of the 3-second windows where BirdNET also positively detected the species and intersected the tag.
Amplitude : peak amplitude (in dBFS) of the tag
Abundance: abundance of the species made in the tag. If TMTT, the icon will appear as

WildTrax uses the BirdNET API and returns the maximum probability from all the 3-second windows that intersected the tag. Note, results from other species are not returned. 

WildTrax returns the maximum value in all of the 3-second windows (in dashed blue lines here) generated by BirdNET that intersect the tag. The value indicates the probability of BirdNET having detected the species in that interval. If BirdNET doesn‚Äôt detect the same species, the probability will be 0.
You can also click on the  button which opens the Help menu describing everything from the legend to keyboard shortcuts and tag selection methods so you can customize your verification workflow the way you want.

Clicking on the top-right corner of the single tag panel  opens the detailed verification window. This window allows you to manipulate the audio and spectrogram parameters in order to verify the tag. The main sections of the detailed verification window include:

Task link (in the header)
Action buttons
Tag details
Spectrogram
Filters
The task link will open a new tab and jump back to the task to view where the tag took place, highlighting the tag in black. This is useful if you need more context beyond what is available in the detailed verification window.

Actions are where you can quickly validate the tag after you‚Äôve done any filtering or audio manipulation.

 to verify. The icon will turn green when the tag is verified.
Screen Shot 2022 01 27 at 12.31.09 PM to rate the tag following eBird guidelines.
 to delete. This will delete the tag from the system. The changes will also be tracked in the audit table of the task. 
Tag details in the left column summarize other useful information about the media and tag in order to help make a decision on the verification of the tag.

Minimum frequency: minimum frequency of the tag
Maximum frequency: maximum frequency of the tag
Length: length of the recording (seconds)
Default channel: indicates the channel used for default verification. If one of the channels were malfunctioning, the better channel will appear by default. 
BirdNET probability: maximum value returned from BirdNET
Peak dBFS: maximum amplitude of the tag

You can manipulate the audio and spectrogram using the different filters and editors located below the tag. These include the following settings that you can combine in any way you‚Äôd like to generate the best-looking and -sounding spectrogram to verify the tag. 

Amplify: increases the gain, or amplitude, of the media.
Noise filter: runs a noise profile on the tag and attempts to eliminate noise.
Channel filter: Select the channel you want to display and listen to (Left or Right). By default, the left channel is visible while both channels are audible.
Z Contrast: Contrast range in dB. Default is 120 dB. This sets the dynamic-range of the spectrogram to be the selected value dBFS to 0 dBFS. This may range from 20 to 180 dBFS. Decreasing dynamic-range effectively increases the ‚Äòcontrast‚Äô of the spectrogram display, and vice versa.
Z Brightness: Sets the upper limit of the Z-axis in dBFS. A negative number effectively increases the ‚Äòbrightness‚Äô of the spectrogram display, and vice versa. 
Y Scale: Expand the number of pixels displayed on the Y axis. Default is 1x. A larger number stretches the spectrogram vertically.
Frequency filter toggle: when turned on, limits the audio file to playing only the frequency bounds of the tag. Helpful for eliminating other bandwidths to more clearly hear the signal. 


# Camera Projects üì∏ {#sec-camera-projects}

![](assets/camera-projects.png){.lightbox}

The goal of a camera project is to upload image sets (i.e., tasks), process tasks (i.e., tag species and individuals within images), verify tags, and publish the results. The main interface you will interact with when processing image sets is the camera project dashboard. Projects are purposeful groupings of an organization‚Äôs media and metadata to answer specific questions or implement a study design.

## Camera data concepts

A **remote camera** can be deployed at a location for a short or long period of time. One or several units can be deployed at a single location for years, swapping out the batteries and SD cards every so often depending on usage, or the unit(s) can be moved to a new location. This flexibility provides great benefit to a user or researcher, as the only limitation to data collection is storage space and battery life. Depending on the length of time these units will be in the field prior to being serviced, camera settings can be changed to optimize battery life. When developing a remote camera sampling design for questions related to density estimation, relative abundance, occupancy modeling, etc., strong considerations should be made regarding the length of time in the field, number of units to install and the distance between units. Resources on camera deployment methods, sampling protocols and analytical approaches can be found in the [Resources](https://wildtrax.ca/resources/) section.

## Camera project management

![](assets/camera-project-page.png){.lightbox}

Projects are purposeful groupings of an organization‚Äòs media and metadata to answer specific questions or implement a study design. Projects can be one of three sensors: ARUs, cameras or point counts. For each of these sensor types, a collection of tasks (ARU), image sets (camera) or surveys (point counts) are processed or uploaded in order retrieve species data.

WildTrax requires at least one administrator per project. Project administrators manage the upload of media, user management and assignments, auditing and species verification, and project publication. Organization administrators create the project and assign a project administrator to manage it. These administrators also add read-only members or share location reports with other WildTrax users.

The general life cycle of a project involves:

Creating a project 
Adding users to the project 
Uploading media or data depending on the sensor
Creating or uploading tasks or surveys
Creating (processing) or uploading tags or observations
Verifying and quality controlling tags

### Create a camera project

### Camera project settings {#sec-camera-project-settings}

### Species assignment

### User assignment

### Uploading images and creating tasks

### Image sets



### Image auto-classification

The use of remote cameras can lead to the capture of hundreds, thousands or even hundreds of thousands of images in a single image set. The large data sets collected are a benefit to users; however, image processing is also usually a bottleneck to producing meaningful data in a timely manner. The time required for humans to process each image and categorize animals or humans can be incredibly time-consuming and inefficient. WildTrax‚Äôs auto-tagger features allow you to reduce the time required to review remote camera images by applying tags to images, or **auto-tagging** before you begin manually tagging. WildTrax's current auto-tagging classification includes:

-   MegaDectector Version 6 (MDV6-yolov10-e) from [Pytorch Wildlife](https://github.com/microsoft/CameraTraps).
-   The **STAFF/SETUP tagger**

The STAFF/SETUP tagger is a setting used to select the application of the STAFF/SETUP tag automatically to image sets. The auto-tagger will automatically tag images of humans that occur within the first or last series as ‚ÄúSTAFF/SETUP‚Äù (using a 5-minute series gap), unless there are \<2 images auto-tagged as human, or the STAFF/SETUP tag has already been applied.

Once you‚Äôve applied auto-tagger setting in [Camera project settings](#sec-camera-project-settings), any image data uploaded into the project will be run through the auto-tagger based on your selection of classifier categories before they become available for tagging.

### Syncing data to camera projects

Administrators can benefit from managing only the locations from the media in the project.

To sync location information for locations present in the project:

Click on the ‚ÄúManage‚Äù button > ‚ÄúDownload Location CSV‚Äù to obtain the ‚Äúmanage tags CSV‚Äù, which includes the current list of tags in the project.
Make the changes to location information you‚Äôd like. Note that you cannot add or delete locations using the Manage button from the project page.. However, you can add or delete locations using the Manage button on the Organization > Location page. Attempting to add, change, or remove data in the location column will result in an error on re-upload into WildTrax.
Re-upload the modified CSV by clicking ‚ÄúManage‚Äù >  ‚ÄúUpload Location CSV.‚Äù

::: {.callout-tip icon="false" collapse="true"}
Batch upload processes in WildTrax support **add** and **update** operations only; deletions are not allowed. For example, if you accidentally upload an empty CSV, no existing data will be deleted.
:::

### Downloading reports and media

### Merge projects

### Delete a project

### Publishing a project

## Image Tagging

Tagging images in WildTrax is relatively flexible in that the user can be as general or as detailed as your question requires. Tagging entails the application of one or more tags, composed of a species, sex, age and number of individuals, to each image. In the future, WildTrax will allow for the application of additional tags such as coat colour, snow depth, etc.

From the tagging screen, select one or more images for tagging in multiple ways:

Click on the image to select it.
Click and drag your cursor over groups of images
Using Shift, you can click on the first image; then, holding Shift, click on the last image to select all images in between.
Using Ctrl, you can select multiple images that are not in consecutive order. This includes being able to drag boxes around multiple subsets of images.
Select images in the panel on the left-hand side of the screen. Note: Selected images will be highlighted in teal in the number panel. Press ESC at any time to deselect highlighted images.
Apply tag(s) to selected image(s) using the tagging window. With image(s) selected, click on ‚ÄúTag Selected X,‚Äù where X represents the number of images you have highlighted for tagging, and fill in applicable information.

![](assets/image-tagging-page.png){.lightbox}

The tagging form differs when tagging a single image (Single image tagging form) compared to when tagging multiple images (Batch image tagging form):

Single image tagging form:

### Tagging page controls and settings

### Individual-level tags

The individual(s)-level tags refer to a tag applied to one or more individuals with the same combination of characteristics (i.e., all are adult males displaying the same behaviour). Note that what constitutes the ‚Äúsame combination‚Äù will depend upon the tagging field options selected within camera project settings. Individual(s)-level tags appear in the upper gray portion of the tagging page.

The following fields can be optionally selected in the camera project settings to classify characteristics of one or more individuals (if they have the same characteristics) in a tag.

Some of the tagging field options are ‚Äúone-to-many fields,‚Äù meaning you can select multiple options that apply. In the tag report, one-to-many fields will occur as a comma-separated list.

Since more than one individual-level tag may occur for a single image, it‚Äôs important to note that each tag corresponds with a unique row in the tag report (see section 7.1 Data Downloads).

Species
The species menu is divided into Mammals, Birds, and Human tags. Common and frequently used species appear at the top of the drop-down menu to facilitate quick tagging.

Special species tags are also used:

Unidentified: a species tag used if the individual in the image cannot be identified based on visible features. This is often used when the only images of an individual are blurs, blotches of fur, etc.
NONE: a species tag used for motion-activated images with no individual(s) present.
STAFF/SETUP: a species tag used for the series of photos taken while staff are setting up or taking down the camera (humans that occur within the first or last series, using a 5-minute series gap). This tag is applied automatically if the STAFF/SETUP auto-tagger is selected in the project settings.
Count (camera)
Count is the number of individuals of a particular species, age, sex, behaviour, etc. (i.e., applies to a specific tag where all other fields remain the same rather than an image). For example, if adults and juveniles occurred together in an image, the count would not equate to the number of both adults and juveniles, but rather, a separate tag for juveniles should be applied, and the counts in the separate tags should include the number of adults and the number of juveniles, respectively.

The default count for all wild animals is ‚Äò1.‚Äô The number can be changed if the count is greater than one. The default count for domestic animals, birds, vehicles, and humans is ‚ÄòVNA.‚Äô Users can also input VNA if they do not want to collect information in this field.

Age class
Age class is the categorical age class (choose one) of individual(s) in a tag (when identifiable).

Age class options:

Adult (Adult; default for mammals): an animal that is old enough to breed.
Juv (Juvenile): an animal during its first summer [mammals older than neonates but still requiring parental care]. The juvenile tag is only used for an animal‚Äôs first summer when they have apparent juvenile features, such as spots.
UNKN (Unknown): the age class of the individual is unclear.
VNA (Variable not applicable; default for domestic animals, birds, and humans): the tag does not apply, or the user is not interested in collecting information for this field.
Sex class
Sex class is the categorical sex class (choose one) of individual(s) in a tag (when identifiable). For example, ungulate species such as deer, elk, and moose can be identified by sex class based on the presence of antlers, but antlers are not manifested year-round. Therefore, it is recommended that antler-less ungulates are only tagged as a female between May 15 and October 1. Outside of these dates, if antlers are not present, the default of UNKN should be used. Some species, such as bears, are often photographed with their young. When an adult mammal is with a juvenile, it can be assumed to be Female and tagged as such.

Sex class options include: Male, Female, Unknown (default), and VNA (variable not applicable). Users can select VNA if they are not interested in collecting this information.

Behaviour
Behaviour is a one-to-many field (choose all that apply) used to classify behaviour(s) of mammals (reported as a comma-separated list when syncing tags).

Behaviour options include: Travelling, Standing, Running, Feeding/Foraging, Drinking, Bedding, Inspecting, Inspecting Camera, Vigilant, Territorial Display, Rutting/Matting, Unknown, Other, and VNA (variable not applicable; default).

Health/Disease
Health/disease is a one-to-many field (choose all that apply) used to classify descriptors of health and/or disease status (reported as a comma-separated list when syncing tags).

Health/Disease options include: Poor Condition, Discolouration, Hair loss, Lumps, Scarring, Injured, Malformed (environmental and/or genetic), Diseased, Ticks, Mange, Dead, and Other.

Direction of travel
Direction of travel is a categorical field (choose one) used to classify the direction of travel of moving individual(s). The 12 categories represent the 12 positions of a clock. Assuming the camera always faces 12 o‚Äôclock position, the option entered for a moving individual should represent the clock position that an animal moves towards in relation to the direction the camera faces. For example, if the animal travels from left to right, and the movement is perpendicular to where the camera faces, the direction of travel would be ‚Äú3 -o- Clock.‚Äù

Direction of travel options include: 1 -o- Clock, 2 -o- Clock, 3 -o- Clock, 4 -o- Clock, 5 -o- Clock, 6 -o- Clock, 7 -o- Clock, 8 -o- Clock, 9 -o- Clock, 10 -o- Clock, 11 -o- Clock, and 12 -o- Clock.

Coat colour
Coat colour is a one-to-many field (choose all that apply) used to classify the coat colour(s) of mammals (reported as a comma-separated list when syncing tags).

Coat colour options include: Beige, Cream, Brown, Chocolate Brown, Dark Brown, Black, Blonde, Cinnamon, Grey, Red, Orange, Yellow, White, Melanistic, and Other.

Coat attributes
Coat attributes is a one-to-many field (choose all that apply) used to classify attributes of mammals‚Äô coats (reported as a comma-separated list when syncing tags).

Coat attributes tag options include: Spots, Speckled, Salt-pepper, Stripes, Cross-Phase, Chest Blaze, and Other.

Antler tine attributes
Antler tine attributes is a combined field (choose one combination) used to document information on antler tine attributes, including antler position (the side of the rack being categorized), tine count (the number of antler tines present) and tine count precision (the precision of the tine count). Users will only be able to apply this tag to mammal species with antlers (e.g., Moose, White-tailed deer, etc.).

Antler tine attributes:

Antler position: the side of the rack being categorized (options include: Left, Right, and Symmetrical)
Tine count: the number of antler tines present.
Tine count precision: the precision of the tine count (options include: Exact, Approximate, and At least)
A screenshot of a computer

Description automatically generated

Note that the three antler tine attributes are concatenated into one value in the resulting tag report.

Collar
Collar flags are used to identify individuals affixed with a collar (e.g., a GPS collar; may be interpreted as ‚Äúoff-leash‚Äù for Domestic Dogs) (reported as ‚ÄòTRUE‚Äô or ‚ÄòFALSE‚Äô when syncing tags).

Ear tag
Ear tag flags are used to identify individuals with ear tags (reported as ‚ÄòTRUE‚Äô or ‚ÄòFALSE‚Äô when syncing tags).

Interacting with human feature (IHF)
Interacting with human feature (IHF) flags are used to indicate when individual mammals use or interact with human features (e.g., an animal walking in the adjacent forest vs. along the fence, or digging in a compost pile) (reported as ‚ÄòTRUE‚Äô or ‚ÄòFALSE‚Äô when syncing tags).

Tag needs review
Tag needs review flags are applied when species attributes are unclear and need to be checked. Each individual-level tag in an image is associated with a review tag, so it is clear which tag needs to be reviewed (reported as ‚ÄòTRUE‚Äô or ‚ÄòFALSE‚Äô when syncing tags).

Tag comments
Tag comments are any comments entered by the observer to describe any additional details about the individual(s)-level tag. Note there is also a field to document image comments.

Field of View (FOV) is the extent of a scene that is visible in an image (Wearn & Glover-Kapfer, 2017).

For remote cameras, the camera‚Äôs FOV is influenced by how the camera is set up (i.e., camera height and angle, slope, etc.), and it often remains largely unchanged throughout a deployment. However, a camera‚Äôs FOV can change during deployment, such as snow blocking the lens or because the camera was nudged by an animal moving past it (e.g., and now faces another tree rather than an open area). When the camera‚Äôs FOV has changed when compared to the setup view, users should use the image FOV tags to document images that shouldn‚Äôt be included as part of the observation period (and thus the sampling effort). It is important to use the image FOV tags correctly since they allow for the correct estimation of each camera‚Äôs sampling effort.

FOV
Field of View tags are only used when the camera‚Äôs FOV has changed significantly (for 3+ hours) compared to the FOV at setup. When this occurs, the images are considered to be ‚ÄòOut of range,‚Äô and the observation period ends for the camera. The image(s) may be motion or time-lapse-triggered images.

FOV ‚ÄòOut of Range‚Äô criteria:

The camera‚Äôs FOV changed for 3+ hours
The change in FOV was ‚Äúsignificant‚Äù, which may occur due to:
Loss of visibility ‚Äì e.g., the lens is more than 50% covered (by snow, vegetation, fallen trees, etc.). Discretion is used where (e.g.) cattle are leaning on a post and making the camera go in and out of position repeatedly. In such cases, the camera is said to be not working properly the whole time this is happening.
Major changes in the roll, pitch, and yaw of the camera:
Roll ‚Äì the tilt is more than 30 degrees from level. Note: The lines in the image below show the angle to which the horizon would need to rotate to be considered out of range.
Pitch ‚Äì the camera‚Äôs angle shifted upwards or downwards such that the pole (if used) is now beyond the bottom of the image or above the center of the image.
Yaw ‚Äì the bottom of the pole (if used) is out of view beyond the right or left side of the image.
Application of Image FOV tags
There are four potential FOV tags, ‚ÄúWithin,‚Äù ‚ÄúOut of Range,‚Äù ‚ÄúEND ‚Äì Last good image in FOV,‚Äù and ‚ÄúSTART ‚Äì First good image in FOV‚Äù. Importantly, the Out of Range tag is automatically applied to the images between the END and START tags (if applied) after a FOV review has been completed.

If the FOV remains unchanged (or altered, but for < 3 hours) compared to the setup view, the camera‚Äôs FOV is assumed to be ‚ÄúWithin‚Äù the normal range (the default), and the observation period includes the entire deployment. However, what if, for example, you‚Äôre tagging an image set with ~2,500 images, and there was a period in the middle of the deployment (e.g., images 1001-1551) where snow covered the lens of the camera for more than 3 hours, and thus, these images should be considered ‚ÄúOut of Range.‚Äù However, users do not need to manually apply the Out of Range tag manually since WildTrax will populate it automatically after the field of view review if the END and/or START tags are applied. For the first 999 images, the user can leave the image FOV as the default (‚ÄúWITHIN‚Äù) since the FOV remained the same as the setup view, and thus the observation period began with the first image and continued until the FOV changed. Users should apply the END tag to image 1000 since it is the last image with the correct FOV and signifies the end of the observational period. Since the snow melted after image 1551, the user should apply the START tag to image 1552 to signify that the observation period has recommenced.

To summarize, follow these instructions to use the FOV tags correctly:

WITHIN (default): applied to images where the camera is assumed to have the camera setup FOV (i.e., is ‚ÄúWITHIN‚Äù the normal range). The Field of View field defaults to ‚ÄòWITHIN‚Äô as images are assumed to be within range.
Out of Range: applied to images where the camera‚Äôs FOV has changed significantly (for 3+ hours) compared to the setup FOV. This tag does not need to be applied manually; WildTrax will complete the process automatically during the Field of View review. Images may be motion or time-lapse images.
END ‚Äì Last good image in FOV: if the FOV has changed significantly (for > 3 hours), apply to the last image with the correct FOV (the camera setup FOV) before the FOV changed (e.g., the last image before snow covers the lens or a cow leans against the camera) to signify the end of the observational period.
Note that the ‚ÄòEND‚Äô and ‚ÄòSTART‚Äô tags are only used if the view changes compared to the set-up images.
START ‚Äì First good image in FOV: applied if a) the END tag was applied, and b) if the camera‚Äôs FOV returns to the correct FOV (the camera setup FOV); applied to the first image captured with the corrected FOV (e.g., snow melts or the cows stops leaning against the camera) to signify that the observation period has recommenced.
Don‚Äôt apply a ‚ÄòSTART‚Äô tag at the beginning of an image set to indicate that the camera has been successfully set up.
Note that the ‚ÄòEND‚Äô and ‚ÄòSTART‚Äô tags are only used if the view changes compared to the set-up images.
After the Field of View review is complete (see the section on Field of View review), the ‚ÄòOut of Range‚Äô tag will be automatically applied to the images between the END tag (end of the observation period) and the START tag (beginning of a new observation period).
Snow presence
Snow presence flags are applied to images where snow is present on the ground (reported as ‚ÄòTRUE‚Äô or ‚ÄòFALSE‚Äô when syncing tags). If snow is in the air (i.e., it is snowing) but not on the ground, snow presence should not be flagged.

Image snow depth (m)
Image snow depth (m) is the depth of snow (in metres) at the distance at which the camera detects motion at the ground/snow surface level.

Image water depth (m)
Image water depth (m) isthe depth of water (in metres) at the distance at which the camera detects motion at the water‚Äôs surface.

Fire presence
Fire presence flags are applied to images where the camera was clearly triggered by fire. Note: there may be animals present in these images or not (reported as ‚ÄòTRUE‚Äô or ‚ÄòFALSE‚Äô when syncing tags).

Malfunction
Malfunction flags are applied to images when it appears that the camera is not working properly (e.g., images are completely black or pixelated) (reported as ‚ÄòTRUE‚Äô or ‚ÄòFALSE‚Äô when syncing tags).

Nice
Nice flags are used to highlight high-quality images, so they are easier to find at a later date (reported as ‚ÄòTRUE‚Äô or ‚ÄòFALSE‚Äô when syncing tags).

Image comments
Image comments are comments entered by the observer to describe any additional details about the image. Note: there is also a field to document individual(s)-level comments.


### Image-level tags

Image-level tags are applied based on information that can only occur once per image (e.g., snow or fire is either present in an image or it is not). Image-level tags are displayed in the larger grey box at the bottom of the tagging page. Note that this box will shift down as new tags are added.

### Filter panel

Filters panel (b): The filters panel can be used to search for tagged images or filter for certain parameters within an image set. You can filter for tagged images containing any of the tagging field options (see section 5.2.3 ‚Äì Tag types for more information), such as tags of a specific species, sex, or age, as well as a variety of descriptive tags, date ranges and field of view. From this window, you can view all hidden images (time-lapsed and auto-tagged) as well as select a date and time of images you want to view. 

Number of images per page (e): where you can define how many images are displayed per page.

Bounding box display threshold (f): the minimum classifier confidence level for which bounding boxes will be displayed for the selected detection categories. The default is managed in the camera project settings. 

bounding box
Page numbers (g): depending on the number of images you display per page, your corresponding number of pages will increase or decrease.

page numbers
Image information icon (h): The icon at the bottom right-hand corner of an image can be used to see the image metadata (e.g., Equipment make, Equipment model, Flash mode, etc.). The icon will also display the image URL, which can be used to download a specific image.

### Image classifiers

### Tagging scenarios

There are four main tagging scenarios you may encounter:

‚â• 1 images / 1 individual / 1 species: if you select one or more images with a single individual of a species, then a single tag is applied. Once the tag fields are completed, click ‚ÄúSave All and Close‚Äù to apply the tag.
1 image / >1 individuals / 1 species: if you select a single image that contains > 1 individual of a single species, but age and/or sex differ among these individuals, then multiple tags are applied. Once you have completed the tag fields for the first individual, click  to create a new tag for the next individual. Example: an image with a female moose with a calf. In this case, you would create a unique tag for each individual.
3) 1 image / ‚â• 2 species: If you select a single image that contains > 1 species, then multiple tags are applied. Once you have completed the tag fields for the first species/individual, click ‚ÄúAdd Tag‚Äù to create a new tag for the next species/individual. Example: an image where a deer triggered the camera and a coyote was also captured in the background. In this case, you would tag the deer and then click ‚ÄúAdd Tag‚Äù to create a second tag for the coyote (or vice versa).

4) >1 image / >1 individuals / 1 species / tags differ: If you select multiple images that contain > 1 individual of a single species and age, sex, or any other tags (e.g., behaviour) differ among these individuals, then multiple tags are applied. Once you have completed the tag fields for the first individual, click ‚ÄúAdd Tag‚Äù to create a new tag for the next individual.

Update all untagged
Images with abundant species that will all have the same tag, such as Domestic Cows, may be left untagged until the end. Once all other images in the image set (including NONE) have been tagged, you can select the Updated All Untagged button and enter the Domestic Cow tag in the tagging window. Doing so will tag all remaining untagged images (on all pages) as Domestic Cow.  The Updated All Untagged button can be used for any species whose tag attributes (e.g., Individual count, Sex class, or Age class) defaults to ‚ÄòVNA.‚Äô Thus, the button can be used for all domestic animals, humans, or NONE. This button cannot be used if the tag attributes vary.

### Field of view review

A Field of View review is completed is only if an ‚ÄòOut of Range,‚Äô ‚ÄòEND,‚Äô and/or ‚ÄòSTART‚Äô tag was previously applied during the tagging process, and after all images in an image set have been tagged. 

### Species verification

Species verification is completed as part of a quality control step within WildTrax to ensure the accurate application of tags. This step is only carried out when all image sets within a project have a status of ‚ÄùTagging Complete‚Äù. In general, all wild mammals are double-checked. Domestic and bird species are verified at the discretion of the project administrator, who assigns species to taggers.

The main objectives for species verification are:

Ensure manually-applied species tags are correct
Ensure context-tagged species tags are correct
Ensure auto-tagged species tags are correct (if applicable)
Conduct additional analyses on verified images
To complete species verification:

Access your assigned species through the Verify Species tab of the project page.

Checks to complete during species verification: Correct species ID tag(s) and use of attributes tags.
If errors are found, you can edit the tag by open the tagging form either by: clicking on the image and selecting the ‚ÄúTag Selected‚Äù button in the top right-hand corner of the screen or clicking on the tag below the image. In both cases, edit the tag in the tagging form and click ‚ÄúSave All and Close.‚Äù
Once all images on a page have been checked, click on the ‚ÄúVerify Species‚Äù button (e.g., Verify Canada Lynx) at the bottom of the screen. The next page of images to verify will automatically appear. When all images on a page are verified, the images and page navigation boxes turn green to indicate they are complete.

Notes on species verification

If a tag was given a ‚ÄúTag Needs Review‚Äù tag during the first round of tagging, that image will have an orange border around it in the side panel to emphasize that this image‚Äôs species tag needs to be reviewed with extra care.
‚ÄòUnidentified‚Äô and ‚ÄòTag Needs Review‚Äô tags: Images labelled as ‚ÄòUnidentified‚Äô and ‚ÄòTag Needs Review‚Äô are either unidentifiable species and shapes that triggered the camera or identifications that taggers are not 100% sure of, respectively. These tags should be double-checked to verify that tags have been applied correctly. Tags with the ‚ÄòTag Needs Review‚Äô flag that cannot be identified but still possess identifying features should remain as ‚ÄòTag Needs Review.‚Äô However, if the species in the tag cannot be identified and there are no identifiable features, re-tag the species as ‚ÄòUnidentified‚Äô and remove the ‚ÄòTag Needs Review‚Äô tag.

### Location verification

Double-checking the location information is an easy but important task. It should be completed for all applicable tasks where reference signs was used during field set-up and/or pick-up activities. If this does not apply, please continue to the section on Tagging images.

If applicable, you can review the initial STAFF/SETUP photos and compare the location name on the reference sign against the photo labels on WildTrax. If the STAFF/SETUP portion of the auto-tagger and ‚ÄòHide Auto-‚Äô were selected in the camera project settings, STAFF/SETUP photos will be automatically hidden from view in the image tagging page. If these settings apply, the filter will need to be adjusted to complete location validaton.

1) Click on a task to be taken to the tagging page.

2) On the filter panel, Uncheck image 119

Notify the project admin if there are any mismatches.

# Point Count Projects üê¶ {#sec-point-count-projects}

**Point counts** are a methodology used to survey animals, mainly birds. It involves an observer standing at a pre-determined location for specific period of time, counting the individuals they detect. Specifically for birds, this detection can either be aurally or visually. To account for error in detecting a species, either because it didn‚Äôt sing or wasn't observed during the survey, or the observer misses or misidentifies it, distance estimation and duration intervals are used. All these attributes are what define a survey in WildTrax. When the observer detects a species, it is assigned into a **distance band**, the **duration interval** it was detected, a species and the abundance (or count of individuals). Each detection then becomes an observation.

![](assets/point-count-projects.png){.lightbox}

The majority of the point count data available in WildTrax is through a collaboration with the [Boreal Avian Modelling Centre](borealbirds.ca) who support the conservation of North America‚Äôs boreal birds through high-quality, data-driven and collaborative science and help users harmonize their point count data to a standard that can be used with many other data sets, including ARUs.

## Point count project management

To create a new project, click the Add Point Count Project button in the project dashboard under the point tab. You must be the administrator of at least one organization within WildTrax in order to create a project. The main settings panel will have general information fields and a description of the project. 

The general life cycle of a point count project includes:

-   Creating the project and adding users
-   Uploading surveys
-   Publishing the project

Project Title: The full name used to identify the project as defined by the admin.
Organization: The name of the organization.
Year: The year the data was collected.
Data Source: A field used to specify the original source of the data; this field should be entered if you are importing data from an outside source (e.g., previously tagged data).
Organization description: A short description about the organization..
Status: The status of the project (i.e., ‚ÄúActive,‚Äù ‚ÄúTest Only,‚Äù ‚ÄúPublished ‚Äì Private,‚Äù ‚ÄúPublished ‚Äì Public,‚Äù ‚ÄúPublished ‚Äì Map+Report Only,‚Äù or ‚ÄúPublished ‚Äì Map Only‚Äù).
Once you save your project details, you will be able to manage your users. Select the User Assignment tab to add and view current administrator and read-only project members.

### Syncing point count surveys

You can synchronize your point count with WildTrax in order to batch upload or download and modify and re-upload surveys within the system. The format of the Survey Sync can be found in @tbl-survey-sync.

```{r}
#| eval: false
#| label: tbl-survey-sync

wt_get_sync_columns("download-point-count-by-project-id", project = 804)

```

::: {.callout-tip icon="false" collapse="true"}
Batch upload processes in WildTrax support **add** and **update** operations only; deletions are not allowed. For example, if you accidentally upload an empty CSV, no existing data will be deleted.
:::

You can upload your point count data directly to a project in WildTrax. Here are the required CSV fields : 

Location: The name of the location.
Point count date/time: The date and time that the point count was conducted (in the format ‚Äù YYYY-MM-DD HH:MM:SS‚Äù).
Task method: The method used to process the recording (SPM = 1 tag per individual per species per minute, SPT = 1 tag per individual per species per task, NONE = other methods).
Task distance: The distance method used during the point count.
Observer ID: The unique numeric primary key of the observer that processed the image or recording, or that conducted the point count.
Species common name: The common name of the species that was observed in the tag or point count.
Distance detection: The distance at which the individual/species was detected.
Detection time: The time(s) within a recording or point count that a tagged individual/species was detected (in the format ‚ÄúHH:MM:SS‚Äù).
Abundance: The number of individuals; 1-10, TMTT (too many to tag), or CI1, CI2, CI3 for amphibians.
Detection seen: Was the observation made visually?
Detection heard: Was the observation made acoustically?
Task comments: Comments entered by the observer about the task or point count.
Click on the Manage button and select Upload Surveys. In the new pop-up window, select Choose a CSV file to upload to select your survey data. When the file is uploaded the QA Project Data button will turn green. Click it and WildTrax will ensure that the data you‚Äôre uploading fits the WildTrax standard. This may take a few minutes depending how large your file is. 

Just like with ARU and camera media upload, survey data will also implicitly create locations that don‚Äôt yet exist in the organization. If the location exists, it will automatically join it to the spatial metadata provided the names match. You can merge locations if you need to later. Furthermore, since surveys only typically contain one visit, you can easily autogenerate them in the organization as well.

### Adding location information

## Viewing point count data

![](assets/point-count-survey-page.png){.lightbox}

The point count survey page outlines the observations and many other attributes of the survey. The header contains information on the duration method, distance method, location name and date and time of the survey. It also contains the weather panel indicating the local weather conditions. You can also use the ![](assets/pencil.png){height="20px"} or ![](assets/dropdown-arrow.png){height="20px"} at any time to access any project level functions. Species are then listed on the left side of the page with their appropriate distance and time intervals bins they were detected in. You also have the location map available on the map from where the survey took place.

## Publishing a point count project

To publish a point count project first ensure that all surveys have been added to the project and that all associated metadata is prepared as intended (e.g. check location spatial coordinates to ensure everything is there). Next go to the ![](assets/pencil.png){height="20px"} and go to the Status field. Refer to [Publishing and sharing data](#sec-publishing-and-sharing) for which data privacy level is best for you.
